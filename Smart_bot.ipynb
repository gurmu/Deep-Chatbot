{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smart_bot.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPzxn9TXdUhCzGrmYiBxO1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurmu/Deep-Chatbot/blob/master/Smart_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9mnl2osIuRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8pz2aaCJZQa",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started\n",
        "Import modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlFctlhgJdDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my6BV0KtJkAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_VzstOtJs-R",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation:\n",
        "# Load up the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6kgd7vyJ3wL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path):\n",
        "    \"\"\"\n",
        "    Reads the data from the csv file.\n",
        "    Arguments:\n",
        "        path: a string.\n",
        "    Returns:\n",
        "        dataset: a Pandas Dataframe with two columns, namely: `Question` and `Answer`.\n",
        "        X: a NumPy array representing `Question` column.\n",
        "        Y: a NumPy array representing `Answer` column.\n",
        "    \"\"\"\n",
        "    \n",
        "    # read the csv file into a pandas dataframe\n",
        "    dataset = pd.read_csv(path, usecols=['Question', 'Answer'])\n",
        "    # make sure all cell values are strings; because some of them \n",
        "    # only contain numbers, so they maybe mistaken with other types.\n",
        "    dataset = dataset.applymap(str)\n",
        "    # shuffle the rows of the dataframe and then reset the index\n",
        "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "    X = np.asarray(dataset['Question'])\n",
        "    Y = np.asarray(dataset['Answer'])\n",
        "    \n",
        "    X = np.apply_along_axis(lambda sen: '<start> '+ sen + ' <end>', 0, X)\n",
        "    Y = np.apply_along_axis(lambda sen: '<start> '+ sen + ' <end>', 0, Y)\n",
        "    \n",
        "    return dataset, X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhxQkXbIW3NB",
        "colab_type": "code",
        "outputId": "c4048e95-6802-4b21-f863-b41f2e6ac4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'os' from '/usr/lib/python3.6/os.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OixKyY2piyJB",
        "colab_type": "code",
        "outputId": "d5a6ef56-e90f-43d7-b5db-17c15e79ec12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function posix.getcwd>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybteJilpW8mY",
        "colab_type": "code",
        "outputId": "0fc7fe0e-1601-43d2-9a6a-1a39070be5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd() \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQwL1XO-X5Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLvoeGBDYFCI",
        "colab_type": "code",
        "outputId": "7fc3aed5-4191-407d-b9b5-192764da114b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd path/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/path\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0SdSQK4YI0-",
        "colab_type": "code",
        "outputId": "417f5abd-fedc-48df-af22-b81e20867ce0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-49ac2a95-f4fa-49c0-8a54-6b1643f95c5a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-49ac2a95-f4fa-49c0-8a54-6b1643f95c5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataset.csv to dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33Z0V9_2YsoM",
        "colab_type": "code",
        "outputId": "86846a26-fc71-4bea-ba66-15f81cfd026d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "files_path = '/content/path/'\n",
        "qa_dataframe, X, Y = load_dataset(files_path + 'dataset.csv')\n",
        "qa_dataframe.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i met a girl yesterday . . .</td>\n",
              "      <td>she was a dwarf and she was just shy of waist ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i finally got my shit together .</td>\n",
              "      <td>no more diarrhea !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the most offensive joke i know .</td>\n",
              "      <td>why do pharmacists put cotton wool balls in al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what is a dog ' s favourite easter treat ?</td>\n",
              "      <td>jelly bones !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i used to work in children ' s wear ,</td>\n",
              "      <td>but i grew out of it .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Question                                             Answer\n",
              "0                i met a girl yesterday . . .  she was a dwarf and she was just shy of waist ...\n",
              "1            i finally got my shit together .                                 no more diarrhea !\n",
              "2            the most offensive joke i know .  why do pharmacists put cotton wool balls in al...\n",
              "3  what is a dog ' s favourite easter treat ?                                      jelly bones !\n",
              "4       i used to work in children ' s wear ,                             but i grew out of it ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge5qWhphaYGP",
        "colab_type": "code",
        "outputId": "6701243b-fdda-45c4-a269-a6e1d0afb03f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Number of question-answer pairs in the dataset: {len(qa_dataframe)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of question-answer pairs in the dataset: 176980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfue4BGiarvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAMWya1b6zN",
        "colab_type": "text"
      },
      "source": [
        "Cache all hyperparameters into this dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxRAiIxlb8El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = dict()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10tosrvqcc_7",
        "colab_type": "text"
      },
      "source": [
        "**Choose the size of vocabulary**:\n",
        "\n",
        "This is a hyperparameter that you can play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpLvCpzMchWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 10000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eab_AKFsc5Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mq5XOsQd_-z",
        "colab_type": "text"
      },
      "source": [
        "Now, let's tokenize the data, by converting each sentence (question or answer) to a sequence of integers which represent indices of their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSLTe8EQeBPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentences, vocab_size):\n",
        "  \n",
        "    \"\"\"\n",
        "    Using Tensorflow Tokenizer to turn each sentence into a sequence of integers \n",
        "    (each integer being the index of a token in a dictionary).\n",
        "    Arguments:\n",
        "      X: a list or a NumPy array of strings, where each element is a sentence.\n",
        "    Returns:\n",
        "      tensor: a NumPy ndarray, where each row represents the the sequence of\n",
        "              integers that maps the words of the equivalent sentence in \n",
        "              the `sentences` list to a their indices (for embbedings). shape=(batch_size, )\n",
        "      lang_tokenizer: a Tensorflow Tokenizer which have been fit on `sentences`.\n",
        "    \"\"\" \n",
        "\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, \n",
        "                                                           filters='')\n",
        "    lang_tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    tensor = lang_tokenizer.texts_to_sequences(sentences)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sInSx-SkjKWe",
        "colab_type": "code",
        "outputId": "f49967e8-b2ee-46f5-d356-287c427074eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# all sentences (Questions & Answers)\n",
        "# we need to fit the tokenizer on all sentences; to create word_index and \n",
        "# index_word mapper dictionaries for the most frequent VOCAB_SIZE= 10,000 words.\n",
        "texts = np.concatenate((X, Y))\n",
        "# tokenize the data\n",
        "tensor, text_tokenizer = tokenize(texts, VOCAB_SIZE)\n",
        "\n",
        "print(f\"texts[0]= {texts[0]}\")\n",
        "print(f\"tensor[0]= {tensor[0]}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "texts[0]= <start> i met a girl yesterday . . . <end>\n",
            "tensor[0]= [  1   9 589   5 120 484   3   3   3   2   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMAkgHRZj1nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmtkW2j6kIGw",
        "colab_type": "text"
      },
      "source": [
        "As we see, each sentence has been converted to an array with indices that will be used to map words to their embedding vectors.\n",
        "\n",
        "Now, let's extract back X (for questions) and Y (for answers) arrays from tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IwWWzIij6x1",
        "colab_type": "code",
        "outputId": "085916ed-4934-4dd0-9fbe-10b19aeba0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# extract questions and answers back from tensor\n",
        "X, Y = tensor[:len(X)], tensor[len(X):]\n",
        "\n",
        "print(f\"Shape of X (questions): {X.shape}\")\n",
        "print(f\"Shape of Y (answers): {Y.shape}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X (questions): (176980, 32)\n",
            "Shape of Y (answers): (176980, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvTrZyQnk3jv",
        "colab_type": "text"
      },
      "source": [
        "Get the maximum sequence length for both input and target tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhxA6nfKk5mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_seq_length(tensor):\n",
        "    \"\"\"\n",
        "    Get maximum sequence length in the corpus. And, make sure that all rows in\n",
        "    `tensor` has the same length.\n",
        "    Arguments:\n",
        "      tensor: a NumPy ndarray of shape (batch_size,) where each row represents\n",
        "      indices mapping to words in equivalent sentences.\n",
        "    Returns:\n",
        "      max_len: an integer representing maximum sequence length.\n",
        "    \"\"\"\n",
        "    batch_size = len(tensor)\n",
        "    lengths = [len(sentence) for sentence in tensor]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    # check if all rows in `tensor` has the same length (equal to max_len)\n",
        "    assert lengths == [max_len]*batch_size\n",
        "\n",
        "    return max_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lspQyaDlpnW",
        "colab_type": "code",
        "outputId": "3a7c6803-87d5-4a1a-b179-965b2187cba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Get max_seq_length of input and target tensors\n",
        "max_length_inp, max_length_targ = max_seq_length(X), max_seq_length(Y)\n",
        "print(f\"Maximum sequence length for input (questions) tensor: {max_length_inp}\")\n",
        "print(f\"Maximum sequence length for target (answers) tensor: {max_length_targ}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum sequence length for input (questions) tensor: 32\n",
            "Maximum sequence length for target (answers) tensor: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqZSW-HxmOGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9hiXIPFmTKy",
        "colab_type": "text"
      },
      "source": [
        "Save the arrays as npy files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEIj7r3JmUVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_arrays_path = os.path.join(files_path, 'data_arrays')\n",
        "# create the folder if it does not exist\n",
        "if not os.path.exists(data_arrays_path):\n",
        "    os.makedirs(data_arrays_path)\n",
        "    \n",
        "np.save(os.path.join(data_arrays_path, 'X.npy'), X)\n",
        "np.save(os.path.join(data_arrays_path, 'Y.npy'), Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqkuDXpdmsG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_glove_vectors(glove_file):\n",
        "    \"\"\"\n",
        "    This function reads GloVe vectors from .txt file and \n",
        "    returns a word to vector dictionary.\n",
        "    Arguments:\n",
        "      glove_file: a string path to GloVe word embeddings file.\n",
        "    Returns:\n",
        "      word_to_vec: a Python dictionary that maps words to their embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    import numpy as np\n",
        "    \n",
        "    # open the file\n",
        "    with open(glove_file, 'r', encoding=\"utf-8\") as f:\n",
        "        \n",
        "        words = set()\n",
        "        word_to_vec = {}\n",
        "\n",
        "        # loop over the rows in the file\n",
        "        for line in f:\n",
        "            # read the line, strip it (remove leading and trailing spaces) and split it\n",
        "            line = line.strip().split()\n",
        "            # first item in the list 'line' is the word itself\n",
        "            curr_word = line[0]\n",
        "            # add the word to set of words\n",
        "            words.add(curr_word)\n",
        "            # add the words with its vector representation as a (key, value) pair to the dictionary\n",
        "            word_to_vec[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "\n",
        "    return word_to_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2ElvRTHoPWq",
        "colab_type": "text"
      },
      "source": [
        "## Download GloVe Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLdQisZzoLhC",
        "colab_type": "code",
        "outputId": "311d5317-4a51-49e2-a3a8-7f49e1caa93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-18 19:24:44--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-05-18 19:24:44--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-05-18 19:24:44--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.13MB/s    in 6m 27s  \n",
            "\n",
            "2020-05-18 19:31:11 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkzYZnMFoWe5",
        "colab_type": "code",
        "outputId": "06112af3-0f02-4b8d-bd97-ef9ea675ab71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7ujxU3jqABS",
        "colab_type": "code",
        "outputId": "bf7524a6-6483-4b89-bf3b-be7f8133d447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_arrays  glove.6B.100d.txt\tglove.6B.300d.txt  glove.6B.zip\n",
            "dataset.csv  glove.6B.200d.txt\tglove.6B.50d.txt\n",
            "/content/path\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7tMpvoaqOSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_file = \"/content/path/glove.6B.200d.txt\"\n",
        "word_to_vec = read_glove_vectors(glove_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tBwaBBHqeZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVh6S9nBqsOc",
        "colab_type": "text"
      },
      "source": [
        "# The Model\n",
        "**Choosing Hyperparameters:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL0Sa5t3q1IY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = X.shape[0]\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE \n",
        "embedding_dim = 200\n",
        "units = 512 \n",
        "vocab_size = VOCAB_SIZE + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZx_YyGgs1uj",
        "colab_type": "code",
        "outputId": "f2977157-c8e4-4c8a-ea37-ee43fda4aa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f\"Buffer size: {BUFFER_SIZE}, Batch size: {BATCH_SIZE}, Steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Embedding size: {embedding_dim}, # of units: {units}\")\n",
        "print(f\"Vocab size: {vocab_size}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buffer size: 176980, Batch size: 128, Steps per epoch: 1382\n",
            "Embedding size: 200, # of units: 512\n",
            "Vocab size: 10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X5NDv5ktT-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cache these values into the hyperparameters dictionary\n",
        "hyperparameters['buffer_size'] = BUFFER_SIZE\n",
        "hyperparameters['batch_size'] = BATCH_SIZE\n",
        "hyperparameters['steps_per_epoch'] = steps_per_epoch\n",
        "hyperparameters['embedding_dim'] = embedding_dim\n",
        "hyperparameters['units'] = units\n",
        "hyperparameters['vocab_size'] = vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8XjR-kuc_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCM6FDiRumX_",
        "colab_type": "text"
      },
      "source": [
        "Create the embedding matrix for words in the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkEhofmluo-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(words, word_to_vec, vocab_size, emb_dim):\n",
        "  \"\"\"\n",
        "  Returns an embeddings matrix for the words in the vocabulary.\n",
        "  Arguments:\n",
        "      words: a list of words.\n",
        "      word_to_vec: a dictionary that maps words to their embedding vectors.\n",
        "      vocab_size: an integer which represents the size of the vocabulary.\n",
        "      emb_dim: an integer which represents the dimension of word embeddings.\n",
        "  Returns:\n",
        "      embedding_matrix: a NumPy array with shape of (vocab_size, emb_dim).\n",
        "  \"\"\"\n",
        "\n",
        "  # create embedding matrix\n",
        "  embedding_matrix = np.zeros((vocab_size, emb_dim), dtype=np.float64)\n",
        "\n",
        "  # loop over the words in our vocabulary\n",
        "  for i, word in enumerate(words):\n",
        "    if word in word_to_vec.keys():\n",
        "      # if the current word is in glove vocab, get its glove vector.\n",
        "      embedding_matrix[i, :] = word_to_vec[word]\n",
        "    else:\n",
        "      # if the current word does not exist in the vocabulary, set its vector to zeros.\n",
        "      embedding_matrix[i, :] = np.zeros((emb_dim,), dtype=np.float64)\n",
        "\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXxhqXqhwDGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# since Tensorflow tokenizer word_index still have all words even when \n",
        "# vocab_size is passed while defining the Tokenizer. \n",
        "# So, we need to grab the first 10,000 words.\n",
        "words = list(text_tokenizer.word_index.keys())[:vocab_size]\n",
        "embedding_matrix = create_embedding_matrix(words, word_to_vec, vocab_size, \n",
        "                                           embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYiK-GDEwSD4",
        "colab_type": "code",
        "outputId": "b9b227a0-4af0-43e6-d16e-39529dec796b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: (10001, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbcZP8jkwYIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the embedding matrix\n",
        "np.save(os.path.join(data_arrays_path, 'embedding_matrix.npy'), embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMAGfbLRwhD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGh7vksnwul5",
        "colab_type": "text"
      },
      "source": [
        "Create a tf.data dataset for X and Y with buffer size equal to BUFFER_SIZE and batch size equal to BATCH_SIZE, we will use this dataset to generate batches while training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOfB0cnJwvx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FeLjHWOxskF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HadyHRWvxz1G",
        "colab_type": "text"
      },
      "source": [
        "Example of an input batch that the model will receive while iterating over dataset batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WfYzk3Ox0sb",
        "colab_type": "code",
        "outputId": "16ccfbc2-e3cf-40ef-addc-43b1953890fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 32]), TensorShape([128, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvC3I9MBx_Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GP0bcRIyIL1",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture\n",
        "I'm going to use an encoder-decoder model with Bahdanau's attention, which has been described in detail in this paper:\n",
        "\n",
        "[Effective Approaches to Attention-based Neural Machine Translation](https://)\n",
        "\n",
        "Some properties of the model:\n",
        "\n",
        "The encoder will be a bidirectional encoder with 512 hidden units for each direction, resulting in 1024 cells.\n",
        "\n",
        "Both encoder & decoder will use LSTM as the cell.\n",
        "\n",
        "The decoder will be unidirectional with 1024 hidden units.\n",
        "\n",
        "**The Encoder**\n",
        "Define the bidirectional encoder architecture which will consist of the following:\n",
        "\n",
        "   1. An Embedding layer that will map input sentences to their embeddings. The vocabulary size is equal to VOCAB_SIZE=10,000 and the dimension of embedding is 200 (Note: although a power of 2 embedding size would be more suitable to speed up training time by increasing cache utilization during data movement, thus reducing bottlenecks, but GloVe embeddings do not come with a power of 2 embedding size).\n",
        "\n",
        "   2. A forward & backward (bidirectional) LSTM layer with 512 units for each.\n",
        "\n",
        "The input to the encoder has a shape of (batch_size, ), which is the input array of sentences (questions).\n",
        "\n",
        "The hidden state arrays of the encoder are all of the shape (batch_size, n_units).\n",
        "\n",
        "The output of the encoder has a shape of (batch_size, max_sequence_length, n_units x2) ;the hidden size of the output is equal to double the size of units since the encoder is bidirectional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdxXkt5zyo8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, embedding_matrix, enc_units, \n",
        "                 batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
        "                                                   weights=[embedding_matrix], \n",
        "                                                   trainable=True)\n",
        "        self.bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Propogates the input `x` through the bidirectional encoder and returns\n",
        "        the outputs along with hidden states.\n",
        "        Arguments:\n",
        "            x: a tensor with shape (batch_size, max_seq_length)\n",
        "            hidden: a tuple or a list, with four tensors representing hidden\n",
        "                    and memory states for both the forward and backward LSTMs.\n",
        "                    Each of them having a shape of (batch_size, max_seq_length)\n",
        "        Returns:\n",
        "            output: a tensor representing the output of the encoder with a shape\n",
        "                    of (batch size, max_sequence length, units*2)\n",
        "            state_h: a tensor, with forward and backward hidden states of \n",
        "                     the encoder with a shape of (batch size, units*2)\n",
        "            state_c: a tensor, with forward and backward memory cell states of\n",
        "                     the encoder with a shape of (batch size, units*2)\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        output, fstate_h, fstate_c, bstate_h, bstate_c = self.bi_lstm(x, initial_state = hidden)\n",
        "\n",
        "        state_h = tf.keras.layers.Concatenate()([fstate_h, bstate_h])\n",
        "        state_c = tf.keras.layers.Concatenate()([fstate_c, bstate_c])\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        # forward_state_h forward hidden state output, backward_state_h backward hidden state output\n",
        "        # forward_state_c forward cell (memory) state output, backward_state_c backward cell (memory) state output\n",
        "        return (tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units)), \n",
        "                tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Nguxho111f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inyjb2reZONk",
        "colab_type": "text"
      },
      "source": [
        "Define the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saSLZxRrZPik",
        "colab_type": "code",
        "outputId": "52d86b5e-a49e-4aaf-ae1f-87663c99a6b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_dim, embedding_matrix, units, \n",
        "                  BATCH_SIZE)\n",
        "\n",
        "# usage example\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "\n",
        "sample_output, sample_h, sample_c = encoder(example_input_batch, sample_hidden)\n",
        "print (f'Encoder output shape: (batch size, sequence length, units*2) {sample_output.shape}')\n",
        "print (f'Encoder Hidden state shape: (batch size, units*2) {sample_h.shape}')\n",
        "print (f'Encoder Memory state shape: (batch size, units*2) {sample_c.shape}')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units*2) (128, 32, 1024)\n",
            "Encoder Hidden state shape: (batch size, units*2) (128, 1024)\n",
            "Encoder Memory state shape: (batch size, units*2) (128, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZLjE5w0qmoJ",
        "colab_type": "text"
      },
      "source": [
        "Bahdanau Attention Mechanism\n",
        "The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from Effective Approaches to Attention-based Neural Machine Translation.\n",
        "To learn more about Bahdanau's attention, you can refer to this paper: [Neural Machine Translation by Jointly Learning to Align and Translate](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uqAKPwnqqx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  \n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units*2)\n",
        "        self.W2 = tf.keras.layers.Dense(units*2)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # query hidden state shape == (batch_size, hidden size)\n",
        "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # values shape == (batch_size, max_len, hidden size)\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsfWisphs8LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sbg0HfKuEs5",
        "colab_type": "text"
      },
      "source": [
        "Example of using Bahdanau's attention:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAomKEoeuGQ4",
        "colab_type": "code",
        "outputId": "8d5000ee-1a7f-41a4-dc73-8caf03a327ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# usage example\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_h, sample_output)\n",
        "\n",
        "print(f\"Attention result shape: (batch size, units*2) {attention_result.shape}\")\n",
        "print(f\"Attention weights shape: (batch_size, sequence_length, 1) {attention_weights.shape}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units*2) (128, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (128, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9dIEFkfuRlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKZBrXBZvtGG",
        "colab_type": "text"
      },
      "source": [
        "# The Decoder\n",
        "Define the decoder architecture which will consist of the following:\n",
        "\n",
        "  1. Bahdanau's attention which is applied to the output of the encoder to get the context which will be passed, along with the embeddings of the decoder input, to the LSTM layer of the decoder.\n",
        "\n",
        "  2. An Embedding layer with a vocabulary size of VOCAB_SIZE=10,000 words and an embedding dimension of 200. The embedding takes the decoder input which is of the shape (batch_size, ) and outputs a tensor of the shape (batch_size, 1, embedding_dim).\n",
        "\n",
        "   3. A forward (unidirectional) LSTM layer with 1024 units for each.\n",
        "\n",
        "The shape of the decoder's output is (batch_size, vocab_size) and the decoder hidden state size is of the shape (batch_size, units x2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEE9qNkbwCYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, embedding_matrix, dec_units, \n",
        "                 batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                                   weights=[embedding_matrix],\n",
        "                                                   trainable=True)\n",
        "        self.lstm = tf.keras.layers.LSTM(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        \n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        \"\"\"\n",
        "        Takes decoder input, hidden state and output of the encoder and\n",
        "        returns the decoder's predictions along with decoder hidden state and\n",
        "        attention weights.\n",
        "        Arguments:\n",
        "            x: a tensor with shape (batch_size, 1) which is the decoder input\n",
        "               at some timestep.\n",
        "            hidden: a tensor representing hidden state of the encoder with a\n",
        "                    shape of (batch size, units*2)\n",
        "            enc_output: a tensor representing the encoder's output with a shape\n",
        "                        of (batch size, sequence length, units*2)\n",
        "        Returns:\n",
        "            x: a tensor with shape (batch_size, vocab size) and it's decoder's\n",
        "               output.\n",
        "            state: a tensor that represents the hidden state of the decoder \n",
        "                   and has a shape of (batch_size, units*2)\n",
        "            attention_weights: a tensor that represents attention weights and \n",
        "                               has a shape of (batch_size, sequence_length, 1)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the LSTM\n",
        "        output, state_h, state_c = self.lstm(x)\n",
        "\n",
        "        state = state_h\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG35BcgowQyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAzhl9JW5FUF",
        "colab_type": "text"
      },
      "source": [
        "Define the decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi4sRGFI5GcR",
        "colab_type": "code",
        "outputId": "f25e6477-d204-4b49-ba43-802112810117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "decoder = Decoder(vocab_size, embedding_dim, embedding_matrix, units*2, \n",
        "                  BATCH_SIZE)\n",
        "\n",
        "# usage example\n",
        "sample_decoder_output, dec_h, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_h, sample_output)\n",
        "\n",
        "print(f'Decoder output shape: (batch_size, vocab size) {sample_decoder_output.shape}')\n",
        "print(f'Decoder hidden state shape: (batch_size, units*2) {dec_h.shape}')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (128, 10001)\n",
            "Decoder hidden state shape: (batch_size, units*2) (128, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1o5CFa5LLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95qhVlR25YiD",
        "colab_type": "text"
      },
      "source": [
        "# Defining Optimizer, Loss Function and Metric\n",
        " Define the loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tkdI4ko5epc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                            reduction='none')\n",
        "\n",
        "def compute_loss(real, pred):\n",
        "    \"\"\"\n",
        "    This function returns the loss for model's predictions on a batch \n",
        "    of data in comparison with the real outputs at a timestep.\n",
        "    Arguments:\n",
        "        real: real output, a Tensorflow tensor with a shape \n",
        "              of: (batch_size, max_seq_length)\n",
        "        pred: model's predictions at a certain timestep, a Tensorflow tensor \n",
        "              with a shape of: (batch_size, max_seq_length)\n",
        "    Returns:\n",
        "        A Tensorflow tensor with the loss.\n",
        "    \"\"\"\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBiady7P56EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Jxosdx5_bN",
        "colab_type": "text"
      },
      "source": [
        "Define the perplexity metric:\n",
        "\n",
        "**Note**: I was going to incorporate BLEU score as another metric, but to compute BLEU score on a batch of data, it turns out that we need access the data to count the number of n-grams. In order to do that, we can't use Tensorflow's AutoGraph feature tf.function. Anyways, I tried it and using tf.function was around 2.5 times faster than dropping this feature only to compute BLEU score. In case you want to use BLEU score, you can use nmt's open source implementation which you can find [here](https://), or you can use NLTK's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLo6Sikl6ELS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_perplexity(real, pred):\n",
        "    \"\"\"\n",
        "    This function returns the perplexity for model's predictions on a batch \n",
        "    of data in comparison with the real outputs at a timestep.\n",
        "    Arguments:\n",
        "        real: real output, a Tensorflow tensor with a shape \n",
        "              of: (batch_size, max_seq_length)\n",
        "        pred: model's predictions at a certain timestep, a Tensorflow tensor \n",
        "              with a shape of: (batch_size, max_seq_length)\n",
        "    Returns:\n",
        "        A Tensorflow tensor with the perplexity.\n",
        "    \"\"\"\n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.cast(tf.pow(math.e, tf.keras.backend.mean(loss_, axis=-1)), \n",
        "                   dtype=tf.keras.backend.floatx())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExRXFbR56g6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y_Cijoc7BrL",
        "colab_type": "text"
      },
      "source": [
        "# Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQPRj8j77D4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/path/training_checkpoints'\n",
        "\n",
        "# create the folder if it does not exist\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHIopPWj7fpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxkRQDXz7pYe",
        "colab_type": "text"
      },
      "source": [
        "# TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmJ4GSiu7s_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-12nHE57xTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_file_name =f\"/content/path/logs/metrics_{int(time.time())}\"\n",
        "\n",
        "# create the folder if it does not exist\n",
        "if not os.path.exists(log_file_name):\n",
        "    os.makedirs(log_file_name)\n",
        "    \n",
        "summary_writer = tf.summary.create_file_writer(log_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c68Q00cF8Efg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XE9zfxW8MA4",
        "colab_type": "text"
      },
      "source": [
        "# Define training step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUOSmhOM8PLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    \"\"\"\n",
        "    This function performs a training step for the model on a batch of data.\n",
        "    Arguments:\n",
        "        inp: a tensor, the input to the encoder network which is a batch of \n",
        "              vectors of integers (indices of words) for sentences (questions) \n",
        "              with a shape of (batch_size, encoder_max_seq_len)\n",
        "        targ: a tensor, the real output that the decoder will use to learn \n",
        "              using teacher forcing. It has a shape same as `inp`\n",
        "              which is (batch_size, encoder_max_seq_len)\n",
        "        enc_hidden: a tuple of four tensors, the initial hidden states for the\n",
        "              encoder network, each of the shape (batch_size, n_units*2)\n",
        "    Returns:\n",
        "        batch_loss: loss for the given batch.\n",
        "        batch_acc: accuracy for the given batch.\n",
        "        batch_bleu: bleu score for the given batch.\n",
        "        batch_ppl: perplexity for the given batch.\n",
        "    \"\"\"\n",
        "    \n",
        "    loss = 0\n",
        "    ppl = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Run the input through the encoder and get back the encoder output\n",
        "        # and the hidden states of the encoder.\n",
        "        enc_output, enc_h, enc_c = encoder(inp, enc_hidden)\n",
        "        \n",
        "        # Set the hidden state of the encoder to be the initial hidden state\n",
        "        # of the decoder.\n",
        "        dec_hidden = enc_h\n",
        "\n",
        "        # Define the decoder input which is basically the '<start>' token,\n",
        "        # for every sentence in the batch.\n",
        "        dec_input = tf.expand_dims([text_tokenizer.word_index['<start>']] \n",
        "                                   * BATCH_SIZE, 1)\n",
        "        \n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        # looping over timesteps\n",
        "        for t in range(1, targ.shape[1]):\n",
        "\n",
        "            # Pass encoder output to the decoder along with the decoder\n",
        "            # input and initial hidden state and get back the predictions\n",
        "            # for this batch at the current timestep with the hidden state \n",
        "            # of the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, \n",
        "                                                 dec_hidden, \n",
        "                                                 enc_output)\n",
        "            # predictions shape: (batch_size, decoder_vocab_size)\n",
        "            # dec_hidden shape: (batch_size, units*2)\n",
        "            # attention weights (3rd output that has been discarded) \n",
        "            # shape: (batch_size, decoder_max_seq_len, 1)\n",
        "\n",
        "            # compute the loss\n",
        "            loss += compute_loss(targ[:, t], predictions)\n",
        "\n",
        "            # compute the perplexity\n",
        "            ppl += compute_perplexity(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    # compute the loss for the batch\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    \n",
        "    # compute the perplexity for the batch\n",
        "    batch_ppl = (ppl / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    # get gradients\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss, batch_ppl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guTsnoOF8aBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m}:{round(s,1)}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir_y3gxj_QZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNW0yWb9_Wal",
        "colab_type": "text"
      },
      "source": [
        "## Training the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwvI1LJT_YWE",
        "colab_type": "code",
        "outputId": "84a8ce35-622c-45df-eae7-5dbcb79cd3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(hyperparameters)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'buffer_size': 176980, 'batch_size': 128, 'steps_per_epoch': 1382, 'embedding_dim': 200, 'units': 512, 'vocab_size': 10001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObaDUvlZ_eP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SARxgmL_6Sv",
        "colab_type": "text"
      },
      "source": [
        "Let's train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ42PyUl_7p8",
        "colab_type": "code",
        "outputId": "09122829-6d5e-4b68-8f55-85a21c1d9ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# to cache loss and perlexity over epochs\n",
        "cache = dict({'train_loss': [], 'train_ppl':[]})\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    for epoch in range(EPOCHS):\n",
        "        start_epoch = time.time()\n",
        "\n",
        "        # Initialize encoder hidden state\n",
        "        enc_hidden = encoder.initialize_hidden_state()\n",
        "\n",
        "        total_loss = 0\n",
        "        total_ppl = 0\n",
        "        \n",
        "        # Training the model using the training data\n",
        "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "            \n",
        "            # Train the model on current batch\n",
        "            (batch_loss, batch_ppl) = train_step(inp, targ, enc_hidden)\n",
        "\n",
        "            total_loss += batch_loss\n",
        "            total_ppl += batch_ppl  \n",
        "\n",
        "            # print loss and perplexity for current batch\n",
        "            if batch % 400 == 0:\n",
        "              print(f\"Epoch {epoch + 1}/{EPOCHS} - \"\n",
        "                      f\"batch: {batch}/{steps_per_epoch} - \"\n",
        "                      f\"loss: {batch_loss.numpy()} - ppl: {batch_ppl}\")\n",
        "        \n",
        "        # compute batch loss and perplexity\n",
        "        total_loss = total_loss / steps_per_epoch\n",
        "        total_ppl = total_ppl / steps_per_epoch     \n",
        "\n",
        "        # Log loss and perplexity to TensorBoard for current epoch\n",
        "        with summary_writer.as_default():\n",
        "          tf.summary.scalar('training_loss', total_loss, step=epoch)\n",
        "          tf.summary.scalar('training_perplexity', total_ppl, step=epoch)\n",
        "\n",
        "        # Save (checkpoint) the model every 15 epochs\n",
        "        if ((epoch+1) > 1) and ((epoch+1) % 15 == 0):\n",
        "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "          print(f'Saved checkpoint for epoch {epoch+1}/{EPOCHS} to: {checkpoint_prefix}')\n",
        "        \n",
        "\n",
        "        # cache the loss and perplexity for current epoch\n",
        "        cache['train_loss'].append(total_loss)\n",
        "        cache['train_ppl'].append(total_ppl)\n",
        "\n",
        "        # print loss and perplexity for current epoch\n",
        "        print(f\"Epoch {epoch + 1}/{EPOCHS} - loss: {total_loss} - \"\n",
        "              f\"ppl: {total_ppl}\")\n",
        "        \n",
        "        print(f\"Time taken for epoch ({epoch + 1}): \"\n",
        "              f\"{time.time() - start_epoch} sec\\n\")\n",
        "\n",
        "execution_time = (time.time() - start_time)\n",
        "print(f'Elapsed time: {hms_string(execution_time)}')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30 - batch: 0/1382 - loss: 2.951857566833496 - ppl: 903.2852783203125\n",
            "Epoch 1/30 - batch: 400/1382 - loss: 1.502273440361023 - ppl: 16.80091667175293\n",
            "Epoch 1/30 - batch: 800/1382 - loss: 1.4208929538726807 - ppl: 11.845117568969727\n",
            "Epoch 1/30 - batch: 1200/1382 - loss: 1.277275800704956 - ppl: 12.457500457763672\n",
            "Epoch 1/30 - loss: 1.4310402870178223 - ppl: 21.094200134277344\n",
            "Time taken for epoch (1): 665.8973927497864 sec\n",
            "\n",
            "Epoch 2/30 - batch: 0/1382 - loss: 1.2868998050689697 - ppl: 10.486417770385742\n",
            "Epoch 2/30 - batch: 400/1382 - loss: 1.3770277500152588 - ppl: 10.215579986572266\n",
            "Epoch 2/30 - batch: 800/1382 - loss: 1.1853814125061035 - ppl: 8.428048133850098\n",
            "Epoch 2/30 - batch: 1200/1382 - loss: 1.1145908832550049 - ppl: 6.482759475708008\n",
            "Epoch 2/30 - loss: 1.2030627727508545 - ppl: 8.980830192565918\n",
            "Time taken for epoch (2): 626.9851651191711 sec\n",
            "\n",
            "Epoch 3/30 - batch: 0/1382 - loss: 1.0792791843414307 - ppl: 6.484130382537842\n",
            "Epoch 3/30 - batch: 400/1382 - loss: 1.0975393056869507 - ppl: 6.173291206359863\n",
            "Epoch 3/30 - batch: 800/1382 - loss: 1.0891362428665161 - ppl: 7.844964981079102\n",
            "Epoch 3/30 - batch: 1200/1382 - loss: 1.127518653869629 - ppl: 6.6440277099609375\n",
            "Epoch 3/30 - loss: 1.0923116207122803 - ppl: 6.7339701652526855\n",
            "Time taken for epoch (3): 627.240877866745 sec\n",
            "\n",
            "Epoch 4/30 - batch: 0/1382 - loss: 0.9775137305259705 - ppl: 5.266458511352539\n",
            "Epoch 4/30 - batch: 400/1382 - loss: 1.0824792385101318 - ppl: 5.960600852966309\n",
            "Epoch 4/30 - batch: 800/1382 - loss: 0.9262939095497131 - ppl: 4.802915573120117\n",
            "Epoch 4/30 - batch: 1200/1382 - loss: 0.9681293964385986 - ppl: 4.46601676940918\n",
            "Epoch 4/30 - loss: 1.0012134313583374 - ppl: 5.380537986755371\n",
            "Time taken for epoch (4): 626.7805354595184 sec\n",
            "\n",
            "Epoch 5/30 - batch: 0/1382 - loss: 0.9298996329307556 - ppl: 4.124032020568848\n",
            "Epoch 5/30 - batch: 400/1382 - loss: 0.8818303942680359 - ppl: 4.1142072677612305\n",
            "Epoch 5/30 - batch: 800/1382 - loss: 0.9358959197998047 - ppl: 4.299237251281738\n",
            "Epoch 5/30 - batch: 1200/1382 - loss: 1.0106889009475708 - ppl: 4.478926181793213\n",
            "Epoch 5/30 - loss: 0.9192484617233276 - ppl: 4.437923431396484\n",
            "Time taken for epoch (5): 626.5764427185059 sec\n",
            "\n",
            "Epoch 6/30 - batch: 0/1382 - loss: 0.7479070425033569 - ppl: 3.317336082458496\n",
            "Epoch 6/30 - batch: 400/1382 - loss: 0.7624959349632263 - ppl: 3.5605921745300293\n",
            "Epoch 6/30 - batch: 800/1382 - loss: 0.7322092056274414 - ppl: 3.1980528831481934\n",
            "Epoch 6/30 - batch: 1200/1382 - loss: 0.8125183582305908 - ppl: 4.086061477661133\n",
            "Epoch 6/30 - loss: 0.8428429365158081 - ppl: 3.739037275314331\n",
            "Time taken for epoch (6): 627.1570751667023 sec\n",
            "\n",
            "Epoch 7/30 - batch: 0/1382 - loss: 0.7911574244499207 - ppl: 3.0374555587768555\n",
            "Epoch 7/30 - batch: 400/1382 - loss: 0.7252846360206604 - ppl: 2.877945899963379\n",
            "Epoch 7/30 - batch: 800/1382 - loss: 0.7413878440856934 - ppl: 3.3400721549987793\n",
            "Epoch 7/30 - batch: 1200/1382 - loss: 0.6856116056442261 - ppl: 3.1397080421447754\n",
            "Epoch 7/30 - loss: 0.771192193031311 - ppl: 3.205416679382324\n",
            "Time taken for epoch (7): 627.0579211711884 sec\n",
            "\n",
            "Epoch 8/30 - batch: 0/1382 - loss: 0.7026403546333313 - ppl: 2.6352953910827637\n",
            "Epoch 8/30 - batch: 400/1382 - loss: 0.7258865237236023 - ppl: 2.951201915740967\n",
            "Epoch 8/30 - batch: 800/1382 - loss: 0.7485406398773193 - ppl: 2.970602512359619\n",
            "Epoch 8/30 - batch: 1200/1382 - loss: 0.7936646342277527 - ppl: 3.105536937713623\n",
            "Epoch 8/30 - loss: 0.7044171690940857 - ppl: 2.7958996295928955\n",
            "Time taken for epoch (8): 626.6677885055542 sec\n",
            "\n",
            "Epoch 9/30 - batch: 0/1382 - loss: 0.5680508017539978 - ppl: 2.1526689529418945\n",
            "Epoch 9/30 - batch: 400/1382 - loss: 0.5848109126091003 - ppl: 2.2799253463745117\n",
            "Epoch 9/30 - batch: 800/1382 - loss: 0.7229369282722473 - ppl: 2.5787065029144287\n",
            "Epoch 9/30 - batch: 1200/1382 - loss: 0.5908371806144714 - ppl: 2.200376510620117\n",
            "Epoch 9/30 - loss: 0.6431025862693787 - ppl: 2.4791135787963867\n",
            "Time taken for epoch (9): 626.5197851657867 sec\n",
            "\n",
            "Epoch 10/30 - batch: 0/1382 - loss: 0.5324042439460754 - ppl: 2.0430383682250977\n",
            "Epoch 10/30 - batch: 400/1382 - loss: 0.622464656829834 - ppl: 2.2247793674468994\n",
            "Epoch 10/30 - batch: 800/1382 - loss: 0.6899433135986328 - ppl: 2.4246439933776855\n",
            "Epoch 10/30 - batch: 1200/1382 - loss: 0.5755801796913147 - ppl: 2.2495265007019043\n",
            "Epoch 10/30 - loss: 0.5865216255187988 - ppl: 2.228073835372925\n",
            "Time taken for epoch (10): 626.9717881679535 sec\n",
            "\n",
            "Epoch 11/30 - batch: 0/1382 - loss: 0.5605438947677612 - ppl: 2.0114662647247314\n",
            "Epoch 11/30 - batch: 400/1382 - loss: 0.5037438869476318 - ppl: 1.9611849784851074\n",
            "Epoch 11/30 - batch: 800/1382 - loss: 0.5373851656913757 - ppl: 1.9610761404037476\n",
            "Epoch 11/30 - batch: 1200/1382 - loss: 0.5736596584320068 - ppl: 2.2805182933807373\n",
            "Epoch 11/30 - loss: 0.5346057415008545 - ppl: 2.0299692153930664\n",
            "Time taken for epoch (11): 627.0419399738312 sec\n",
            "\n",
            "Epoch 12/30 - batch: 0/1382 - loss: 0.3586445152759552 - ppl: 1.542673110961914\n",
            "Epoch 12/30 - batch: 400/1382 - loss: 0.5281680822372437 - ppl: 1.957136869430542\n",
            "Epoch 12/30 - batch: 800/1382 - loss: 0.5038480758666992 - ppl: 1.8356086015701294\n",
            "Epoch 12/30 - batch: 1200/1382 - loss: 0.4423123002052307 - ppl: 1.7752940654754639\n",
            "Epoch 12/30 - loss: 0.4879284203052521 - ppl: 1.872711181640625\n",
            "Time taken for epoch (12): 627.3217787742615 sec\n",
            "\n",
            "Epoch 13/30 - batch: 0/1382 - loss: 0.4710995852947235 - ppl: 1.7660861015319824\n",
            "Epoch 13/30 - batch: 400/1382 - loss: 0.3950847387313843 - ppl: 1.6454553604125977\n",
            "Epoch 13/30 - batch: 800/1382 - loss: 0.5017517805099487 - ppl: 1.868699550628662\n",
            "Epoch 13/30 - batch: 1200/1382 - loss: 0.467861145734787 - ppl: 1.7605671882629395\n",
            "Epoch 13/30 - loss: 0.4451393187046051 - ppl: 1.744649887084961\n",
            "Time taken for epoch (13): 627.1347148418427 sec\n",
            "\n",
            "Epoch 14/30 - batch: 0/1382 - loss: 0.3588215708732605 - ppl: 1.5250481367111206\n",
            "Epoch 14/30 - batch: 400/1382 - loss: 0.39398813247680664 - ppl: 1.581426978111267\n",
            "Epoch 14/30 - batch: 800/1382 - loss: 0.5321179032325745 - ppl: 1.907665729522705\n",
            "Epoch 14/30 - batch: 1200/1382 - loss: 0.4014173448085785 - ppl: 1.6268337965011597\n",
            "Epoch 14/30 - loss: 0.40653756260871887 - ppl: 1.640156865119934\n",
            "Time taken for epoch (14): 626.5658824443817 sec\n",
            "\n",
            "Epoch 15/30 - batch: 0/1382 - loss: 0.40639448165893555 - ppl: 1.598259687423706\n",
            "Epoch 15/30 - batch: 400/1382 - loss: 0.3267192244529724 - ppl: 1.4638607501983643\n",
            "Epoch 15/30 - batch: 800/1382 - loss: 0.34031209349632263 - ppl: 1.5110676288604736\n",
            "Epoch 15/30 - batch: 1200/1382 - loss: 0.411582350730896 - ppl: 1.643358588218689\n",
            "Saved checkpoint for epoch 15/30 to: /content/path/training_checkpoints/ckpt\n",
            "Epoch 15/30 - loss: 0.3720841705799103 - ppl: 1.555191159248352\n",
            "Time taken for epoch (15): 628.0877194404602 sec\n",
            "\n",
            "Epoch 16/30 - batch: 0/1382 - loss: 0.2904883027076721 - ppl: 1.386925220489502\n",
            "Epoch 16/30 - batch: 400/1382 - loss: 0.3009854257106781 - ppl: 1.4101228713989258\n",
            "Epoch 16/30 - batch: 800/1382 - loss: 0.35522568225860596 - ppl: 1.5016453266143799\n",
            "Epoch 16/30 - batch: 1200/1382 - loss: 0.3758499026298523 - ppl: 1.5941271781921387\n",
            "Epoch 16/30 - loss: 0.34065306186676025 - ppl: 1.4835169315338135\n",
            "Time taken for epoch (16): 626.7981123924255 sec\n",
            "\n",
            "Epoch 17/30 - batch: 0/1382 - loss: 0.2777845859527588 - ppl: 1.3457207679748535\n",
            "Epoch 17/30 - batch: 400/1382 - loss: 0.321393221616745 - ppl: 1.4441454410552979\n",
            "Epoch 17/30 - batch: 800/1382 - loss: 0.3298320770263672 - ppl: 1.435184121131897\n",
            "Epoch 17/30 - batch: 1200/1382 - loss: 0.3507069945335388 - ppl: 1.4985960721969604\n",
            "Epoch 17/30 - loss: 0.3126879930496216 - ppl: 1.4248946905136108\n",
            "Time taken for epoch (17): 626.631977558136 sec\n",
            "\n",
            "Epoch 18/30 - batch: 0/1382 - loss: 0.2883192300796509 - ppl: 1.3808884620666504\n",
            "Epoch 18/30 - batch: 400/1382 - loss: 0.3329775035381317 - ppl: 1.458817481994629\n",
            "Epoch 18/30 - batch: 800/1382 - loss: 0.25735509395599365 - ppl: 1.3217302560806274\n",
            "Epoch 18/30 - batch: 1200/1382 - loss: 0.33897602558135986 - ppl: 1.4864643812179565\n",
            "Epoch 18/30 - loss: 0.28715211153030396 - ppl: 1.3740262985229492\n",
            "Time taken for epoch (18): 627.6878213882446 sec\n",
            "\n",
            "Epoch 19/30 - batch: 0/1382 - loss: 0.22858139872550964 - ppl: 1.272187352180481\n",
            "Epoch 19/30 - batch: 400/1382 - loss: 0.21362602710723877 - ppl: 1.2498493194580078\n",
            "Epoch 19/30 - batch: 800/1382 - loss: 0.3186090886592865 - ppl: 1.4376494884490967\n",
            "Epoch 19/30 - batch: 1200/1382 - loss: 0.24409544467926025 - ppl: 1.3063161373138428\n",
            "Epoch 19/30 - loss: 0.2659011781215668 - ppl: 1.334126353263855\n",
            "Time taken for epoch (19): 626.8282673358917 sec\n",
            "\n",
            "Epoch 20/30 - batch: 0/1382 - loss: 0.1982957422733307 - ppl: 1.2227917909622192\n",
            "Epoch 20/30 - batch: 400/1382 - loss: 0.19085156917572021 - ppl: 1.2140545845031738\n",
            "Epoch 20/30 - batch: 800/1382 - loss: 0.2253878116607666 - ppl: 1.261888861656189\n",
            "Epoch 20/30 - batch: 1200/1382 - loss: 0.25209471583366394 - ppl: 1.2901220321655273\n",
            "Epoch 20/30 - loss: 0.2445872575044632 - ppl: 1.2962676286697388\n",
            "Time taken for epoch (20): 627.2616882324219 sec\n",
            "\n",
            "Epoch 21/30 - batch: 0/1382 - loss: 0.17787684500217438 - ppl: 1.1890788078308105\n",
            "Epoch 21/30 - batch: 400/1382 - loss: 0.2080879658460617 - ppl: 1.238979458808899\n",
            "Epoch 21/30 - batch: 800/1382 - loss: 0.19550806283950806 - ppl: 1.2196094989776611\n",
            "Epoch 21/30 - batch: 1200/1382 - loss: 0.2482251524925232 - ppl: 1.298408031463623\n",
            "Epoch 21/30 - loss: 0.22617168724536896 - ppl: 1.2650198936462402\n",
            "Time taken for epoch (21): 626.9810087680817 sec\n",
            "\n",
            "Epoch 22/30 - batch: 0/1382 - loss: 0.17057877779006958 - ppl: 1.1832263469696045\n",
            "Epoch 22/30 - batch: 400/1382 - loss: 0.18138691782951355 - ppl: 1.1944950819015503\n",
            "Epoch 22/30 - batch: 800/1382 - loss: 0.21845224499702454 - ppl: 1.2686617374420166\n",
            "Epoch 22/30 - batch: 1200/1382 - loss: 0.20970486104488373 - ppl: 1.2449653148651123\n",
            "Epoch 22/30 - loss: 0.21045708656311035 - ppl: 1.2393803596496582\n",
            "Time taken for epoch (22): 626.9321320056915 sec\n",
            "\n",
            "Epoch 23/30 - batch: 0/1382 - loss: 0.1745874285697937 - ppl: 1.188446044921875\n",
            "Epoch 23/30 - batch: 400/1382 - loss: 0.19369228184223175 - ppl: 1.2043592929840088\n",
            "Epoch 23/30 - batch: 800/1382 - loss: 0.20567965507507324 - ppl: 1.2240707874298096\n",
            "Epoch 23/30 - batch: 1200/1382 - loss: 0.2005002498626709 - ppl: 1.2270373106002808\n",
            "Epoch 23/30 - loss: 0.19588032364845276 - ppl: 1.2161693572998047\n",
            "Time taken for epoch (23): 626.7911398410797 sec\n",
            "\n",
            "Epoch 24/30 - batch: 0/1382 - loss: 0.12989778816699982 - ppl: 1.1198737621307373\n",
            "Epoch 24/30 - batch: 400/1382 - loss: 0.18554171919822693 - ppl: 1.1988232135772705\n",
            "Epoch 24/30 - batch: 800/1382 - loss: 0.18394558131694794 - ppl: 1.2039856910705566\n",
            "Epoch 24/30 - batch: 1200/1382 - loss: 0.19658546149730682 - ppl: 1.2169909477233887\n",
            "Epoch 24/30 - loss: 0.18321864306926727 - ppl: 1.1969265937805176\n",
            "Time taken for epoch (24): 627.8052978515625 sec\n",
            "\n",
            "Epoch 25/30 - batch: 0/1382 - loss: 0.17354527115821838 - ppl: 1.1800812482833862\n",
            "Epoch 25/30 - batch: 400/1382 - loss: 0.16499865055084229 - ppl: 1.164036512374878\n",
            "Epoch 25/30 - batch: 800/1382 - loss: 0.16694436967372894 - ppl: 1.1753792762756348\n",
            "Epoch 25/30 - batch: 1200/1382 - loss: 0.2009650319814682 - ppl: 1.222568392753601\n",
            "Epoch 25/30 - loss: 0.17209571599960327 - ppl: 1.1803475618362427\n",
            "Time taken for epoch (25): 627.3354880809784 sec\n",
            "\n",
            "Epoch 26/30 - batch: 0/1382 - loss: 0.12081451714038849 - ppl: 1.1053507328033447\n",
            "Epoch 26/30 - batch: 400/1382 - loss: 0.1486823707818985 - ppl: 1.1433284282684326\n",
            "Epoch 26/30 - batch: 800/1382 - loss: 0.18961785733699799 - ppl: 1.2034454345703125\n",
            "Epoch 26/30 - batch: 1200/1382 - loss: 0.12987150251865387 - ppl: 1.1295757293701172\n",
            "Epoch 26/30 - loss: 0.16134892404079437 - ppl: 1.1648151874542236\n",
            "Time taken for epoch (26): 627.4504027366638 sec\n",
            "\n",
            "Epoch 27/30 - batch: 0/1382 - loss: 0.13178518414497375 - ppl: 1.121203899383545\n",
            "Epoch 27/30 - batch: 400/1382 - loss: 0.11822903156280518 - ppl: 1.1095584630966187\n",
            "Epoch 27/30 - batch: 800/1382 - loss: 0.1519443392753601 - ppl: 1.1543582677841187\n",
            "Epoch 27/30 - batch: 1200/1382 - loss: 0.17020322382450104 - ppl: 1.1729249954223633\n",
            "Epoch 27/30 - loss: 0.15227268636226654 - ppl: 1.1519726514816284\n",
            "Time taken for epoch (27): 627.2912359237671 sec\n",
            "\n",
            "Epoch 28/30 - batch: 0/1382 - loss: 0.12825843691825867 - ppl: 1.120771884918213\n",
            "Epoch 28/30 - batch: 400/1382 - loss: 0.11922450363636017 - ppl: 1.1054368019104004\n",
            "Epoch 28/30 - batch: 800/1382 - loss: 0.1316283643245697 - ppl: 1.1232956647872925\n",
            "Epoch 28/30 - batch: 1200/1382 - loss: 0.14635443687438965 - ppl: 1.142202377319336\n",
            "Epoch 28/30 - loss: 0.14408130943775177 - ppl: 1.1405457258224487\n",
            "Time taken for epoch (28): 627.3409795761108 sec\n",
            "\n",
            "Epoch 29/30 - batch: 0/1382 - loss: 0.11703145503997803 - ppl: 1.1000707149505615\n",
            "Epoch 29/30 - batch: 400/1382 - loss: 0.1327127069234848 - ppl: 1.1199395656585693\n",
            "Epoch 29/30 - batch: 800/1382 - loss: 0.14812800288200378 - ppl: 1.1481589078903198\n",
            "Epoch 29/30 - batch: 1200/1382 - loss: 0.18484383821487427 - ppl: 1.190386414527893\n",
            "Epoch 29/30 - loss: 0.13773015141487122 - ppl: 1.13188636302948\n",
            "Time taken for epoch (29): 627.6445727348328 sec\n",
            "\n",
            "Epoch 30/30 - batch: 0/1382 - loss: 0.09673718363046646 - ppl: 1.0777804851531982\n",
            "Epoch 30/30 - batch: 400/1382 - loss: 0.12248624116182327 - ppl: 1.1078685522079468\n",
            "Epoch 30/30 - batch: 800/1382 - loss: 0.10573604702949524 - ppl: 1.0881468057632446\n",
            "Epoch 30/30 - batch: 1200/1382 - loss: 0.14177659153938293 - ppl: 1.1369168758392334\n",
            "Saved checkpoint for epoch 30/30 to: /content/path/training_checkpoints/ckpt\n",
            "Epoch 30/30 - loss: 0.13093696534633636 - ppl: 1.1227588653564453\n",
            "Time taken for epoch (30): 629.1067936420441 sec\n",
            "\n",
            "Elapsed time: 5:14:13.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWcQLRstauOw",
        "colab_type": "text"
      },
      "source": [
        "Plot metrics over time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-lcqrlAYcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_metrics(cache):\n",
        "    \"\"\"\n",
        "    Plots loss and perplexity over epochs:\n",
        "    Arguemnts:\n",
        "        cache: a dictionary that contains values over epochs\n",
        "               for both loss and perplexity.\n",
        "    \"\"\"\n",
        "    \n",
        "    # since, items of cache['train_loss'] and cache['train_ppl']\n",
        "    # are tensors, so let's extract values from these tensors.\n",
        "    loss = [tensor.numpy() for tensor in cache['train_loss']]\n",
        "    ppl = [tensor.numpy() for tensor in cache['train_ppl']]\n",
        "    \n",
        "    # Plot the loss\n",
        "    plt.figure()\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot the perplexity\n",
        "    plt.figure()\n",
        "    plt.plot(ppl, label='Training Accuracy')\n",
        "    plt.title('Perplexity')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48tczVrMbQFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "6208b57b-d97f-41a2-ea59-44e579b370f3"
      },
      "source": [
        "plot_metrics(cache)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3RdZZ3/8ffnnNzapNckLaW0lKvclAoR0UHsACIwKjijCOMFZ3AqeMPlOKPjb2Z0vKyfaxx1hlFhECooiKJc5KeIdBC5K6RIoVCUW7E3mrSlbZq2SU7O9/fH2QmnIWnSXHqSsz+vtc7aez97n32ezaGf/eQ5ez9bEYGZmZW/TKkrYGZm+4YD38wsJRz4ZmYp4cA3M0sJB76ZWUo48M3MUsKBb7YHkhZICkkVI9zP5yRdOVr1MhsO+Tp8m6gkrQJmA91AO/BL4GMRsX0UP2MB8DxQGRG58bpPs6FwC98murdHRB1wHNAE/PNQ36gC/xuw1PD/7FYWImIthRb+MZJOlPSApC2Slkta1LOdpN9I+oqk+4EdwMFJ2f+V9JCkbZJ+Jmlmf58jaZqkqyStl7RW0pclZSVVSXpU0seT7bKS7pf0r8nyFyRdm+zmnmS6RdJ2SW+WtFnSq4s+Z5akHZIaR/0/lqWWA9/KgqR5wFnAeuAXwJeBmcCngRv7BOf7gcXAFOCFpOwDwN8Cc4AccOkAH3V1sv5Q4LXA6cCHIqITeB/wRUlHAp8FssBX+tnHycl0ekTURcTdwI+S9/c4H7gzIlqHcvxmQ+HAt4nuFklbgPuAu4E1wG0RcVtE5CNiKdBM4WTQ4+qIeCIichHRlZT9ICJWREQ78C/AuZKyxR8kaXayn09GRHtEtADfBM4DiIgVFE40t1A40bw/IrqHeBzXAOdLUrL8fuAHe/MfwmwwI7rywGwcOCci/rdnQdJ3gHdLenvRNpXAXUXLq/vZT3HZC8l7Gvpsc2BSvv7lXCbT573XUGjV3xgRTw/1ICLid5J2AIskrafwF8StQ32/2VA48K3crKbQWv+7PWzT36Vp84rm5wNdwMY+5auBDqBhD1fXfAf4OfBWSSdFxH1D/HwonCzeB7wI/DQidg18CGZ7z106Vm6uBd4u6a3JD6c1khZJOmCQ971P0lGSJgNfpBC4u3XHRMR64A7g65KmSspIOkTSmwEkvR84Hvgg8AngGkl1/XxWK5AHDu6n7u+kEPrf35uDNhsKB76VlYhYDZwNfI5CsK4G/oHB/1//AYUfZF8EaigEdn8+AFQBTwIvAT8F5kiaD/wn8IGI2B4RP6Tw28E3+6njDgrdPvcnVxKdWFT3Ryj8BXDvEA/ZbMh845WlnqTfANdGRMnvhJW0BFgXEUO+n8BsqNyHbzZOJHfg/iWFyz3NRp27dMzGAUlfAlYAX4uI50tdHytP7tIxM0sJt/DNzFJiXPbhNzQ0xIIFC0pdDTOzCWPZsmUbI2KPYy+Ny8BfsGABzc3Npa6GmdmEIemFwbZxl46ZWUo48M3MUsKBb2aWEg58M7OUcOCbmaWEA9/MLCUc+GZmKVE2gR8RXHrn09z9Rz8C1MysP2UT+JL47j3PcddTLaWuipnZuFQ2gQ/QMKWajds7Sl0NM7NxqawCv762ik3bO0tdDTOzcamsAr+hzi18M7OBlFXg19dVsandLXwzs/6UWeBX89KOTnLd+VJXxcxs3CmrwG+sqyICNu9wK9/MrK+yCvz6umoANrY58M3M+ho08CXNk3SXpCclPSHpkqR8pqSlkp5OpjMGeP8FyTZPS7pgtA+gWEMS+Jva/cOtmVlfQ2nh54C/j4ijgBOBj0o6CvgscGdEHAbcmSzvRtJM4PPA64ETgM8PdGIYDfV1VQC+NNPMrB+DBn5ErI+IR5L5NmAlMBc4G7gm2ewa4Jx+3v5WYGlEbI6Il4ClwBmjUfH+NNQmXTq+NNPM7BX2qg9f0gLgtcDvgNkRsT5Z9SIwu5+3zAVWFy2vScr62/diSc2SmltbhzceztRJFVRmxUa38M3MXmHIgS+pDrgR+GREbCteFxEBxEgqEhFXRERTRDQ1Nu7xwet7qiP1tb75ysysP0MKfEmVFML+uoi4KSneIGlOsn4O0N+oZWuBeUXLByRlY6ZhShWbHPhmZq8wlKt0BFwFrIyIbxStuhXouermAuBn/bz9V8DpkmYkP9aenpSNmfraat9ta2bWj6G08P8MeD9wiqRHk9dZwFeBt0h6GjgtWUZSk6QrASJiM/Al4OHk9cWkbMw01FWzsc0tfDOzvioG2yAi7gM0wOpT+9m+GfhQ0fISYMlwK7i3Guqq2NjeSURQ+OPEzMygzO60hcK1+J25PG0duVJXxcxsXCm7wO+929aXZpqZ7absAr++N/Ddj29mVqzsAr8hGV7B1+Kbme2uDAO/Z3gFd+mYmRUru8CfWesWvplZf8ou8CuzGaZPrvSPtmZmfZRd4APU11Z5THwzsz7KMvALd9u6hW9mVqx8A98tfDOz3ZRl4NfXVXk8HTOzPsoy8Bvqqtm2K0dnLl/qqpiZjRtlGfg9z7bd7GGSzcx6lWXgv3zzlbt1zMx6lGng++YrM7O+yjTwPbyCmVlfgz4ARdIS4G1AS0Qck5T9GHhVssl0YEtELOznvauANqAbyEVE0yjVe488YqaZ2SsNGvjA1cC3gO/3FETEe3rmJX0d2LqH9/95RGwcbgWHo7YqS3VFxs+2NTMrMpRHHN4jaUF/65IHnJ8LnDK61RoZSX62rZlZHyPtw38TsCEinh5gfQB3SFomafGediRpsaRmSc2tra0jrNbLz7Y1M7OCkQb++cD1e1h/UkQcB5wJfFTSyQNtGBFXRERTRDQ1NjaOsFq4hW9m1sewA19SBfCXwI8H2iYi1ibTFuBm4IThft7eqq/ziJlmZsVG0sI/DXgqItb0t1JSraQpPfPA6cCKEXzeXqmvq2bT9k4iYl99pJnZuDZo4Eu6HngQeJWkNZIuTFadR5/uHEn7S7otWZwN3CdpOfAQ8IuIuH30qr5nDXXV5PLB1p1d++ojzczGtaFcpXP+AOUf7KdsHXBWMv8ccOwI6zdsL99t28n0yVWlqoaZ2bhRlnfagsfTMTPrq2wDv2fETD/b1sysoGwDv6eF7yt1zMwKyjbwZ0yuQsLX4puZJco28LMZMXOy77Y1M+tRtoEPvtvWzKxYWQd+4W5bt/DNzKDMA7+hrtqXZZqZJco68OvrqnxZpplZoqwDv6Gumu0dOXZ1dZe6KmZmJVfmge+HmZuZ9SjrwK+v7Xm2rbt1zMzKOvAbpng8HTOzHmUd+PW1Hk/HzKxHWQd+74iZHk/HzGxID0BZIqlF0oqisi9IWivp0eR11gDvPUPSHyQ9I+mzo1nxoZhUlaW2KsvGNrfwzcyG0sK/Gjijn/JvRsTC5HVb35WSssC3KTzA/CjgfElHjaSyw1FfV+0RM83MGELgR8Q9wOZh7PsE4JmIeC4iOoEfAWcPYz8j0lBX5R9tzcwYWR/+xyQ9lnT5zOhn/VxgddHymqRsn+p5mLmZWdoNN/AvAw4BFgLrga+PtCKSFktqltTc2to60t31Koyn48A3MxtW4EfEhojojog88F0K3Td9rQXmFS0fkJQNtM8rIqIpIpoaGxuHU61+NdRVsbm9g+58jNo+zcwmomEFvqQ5RYvvBFb0s9nDwGGSDpJUBZwH3DqczxuJ+toq8gFbdriVb2bpVjHYBpKuBxYBDZLWAJ8HFklaCASwCvhwsu3+wJURcVZE5CR9DPgVkAWWRMQTY3IUe/Dy3bad1CfX5ZuZpdGggR8R5/dTfNUA264Dzipavg14xSWb+9LL4+l0AFNKWRUzs5Iq6zttARqnJCNm+slXZpZyZR/4PS18P9vWzNKu7AN/2qRKshn5blszS72yD/xMRtTXVnk8HTNLvbIPfPB4OmZmkJLAL4yn4xa+maVbSgK/2gOomVnqpSTwqzyAmpmlXioCv76ump1d3bR35EpdFTOzkklH4PvZtmZm6Qj83vF0fKWOmaVYOgLfd9uamaUk8JPxdDZ5PB0zS7FUBP7MpA/fLXwzS7NUBH51RZYpNRVu4ZtZqqUi8AEaffOVmaXcoIEvaYmkFkkrisq+JukpSY9JulnS9AHeu0rS45IeldQ8mhXfW/V1VQ58M0u1obTwrwbO6FO2FDgmIl4D/BH4pz28/88jYmFENA2viqOjoa7a1+GbWaoNGvgRcQ+wuU/ZHRHRc9vqb4EDxqBuo8otfDNLu9How/9b4JcDrAvgDknLJC3e004kLZbULKm5tbV1FKq1u/raal7a0UWuOz/q+zYzmwhGFPiS/g+QA64bYJOTIuI44Ezgo5JOHmhfEXFFRDRFRFNjY+NIqtWvnrttN+9wt46ZpdOwA1/SB4G3Ae+NiOhvm4hYm0xbgJuBE4b7eSPV0HstvgPfzNJpWIEv6QzgH4F3RMSOAbaplTSlZx44HVjR37b7Qk8L30++MrO0GsplmdcDDwKvkrRG0oXAt4ApwNLkksvLk233l3Rb8tbZwH2SlgMPAb+IiNvH5CiGoGfETP9wa2ZpVTHYBhFxfj/FVw2w7TrgrGT+OeDYEdVuFPW28H1pppmlVGrutJ1SXUFVNuNn25pZaqUm8CX5WnwzS7XUBD703G3rwDezdEpV4Bda+O7SMbN0SlXgu4VvZmmWqsDvaeEPcJ+YmVlZS1XgN9RW09mdp60jN/jGZmZlJl2B3/NsW/fjm1kKpSrw62sLN1/50kwzS6NUBX5DXc/dtg58M0uflAV+oUun1V06ZpZCqQr8mbU9ffhu4ZtZ+qQq8CuyGWZMrvSPtmaWSqkKfID6umr/aGtmqZS6wG+oq3IL38xSKXWB7xa+maXVkAJf0hJJLZJWFJXNlLRU0tPJdMYA770g2eZpSReMVsWHq9GBb2YpNdQW/tXAGX3KPgvcGRGHAXcmy7uRNBP4PPB6Cg8w//xAJ4Z9pb62im27cnTm8qWshpnZPjekwI+Ie4DNfYrPBq5J5q8BzunnrW8FlkbE5oh4CVjKK08c+1R9nR9mbmbpNJI+/NkRsT6Zf5HCQ8v7mgusLlpek5S9gqTFkpolNbe2to6gWnvWc/OVf7g1s7QZlR9tozDe8IjGHI6IKyKiKSKaGhsbR6Na/epp4be6H9/MUmYkgb9B0hyAZNrSzzZrgXlFywckZSXT2Duejlv4ZpYuIwn8W4Geq24uAH7Wzza/Ak6XNCP5sfb0pKxk6us8vIKZpdNQL8u8HngQeJWkNZIuBL4KvEXS08BpyTKSmiRdCRARm4EvAQ8nry8mZSUzuSpLTWXGl2aaWepUDGWjiDh/gFWn9rNtM/ChouUlwJJh1W4MSEqebesuHTNLl9TdaQuFH279o62ZpU0qA7/R4+mYWQqlMvDra6t945WZpU4qA79hSqGFn8+P6NYBM7MJJZWBf/jsKeTywd1Pj90dvWZm400qA//MY+aw/7QaLrvr2VJXxcxsn0ll4FdVZPjQmw7moVWbaV5V0tsCzMz2mVQGPsB5J8xjxuRKvvMbt/LNLB1SG/iTqyr4mz87iF8/1cLK9dtKXR0zszGX2sAHuOANC6itynKZW/lmlgKpDvxpkyt574kH8vPH1vGnTTtKXR0zszGV6sAHuPCkg6jIZPife9zKN7PylvrAnz21hr86fi4/WbaGlrZdpa6OmdmYSX3gA3z45EPIdee56r7nS10VM7Mx48AHFjTUctar53Ddb//E1p1dpa6OmdmYcOAnLl50CNs7cvzgwVWlroqZ2ZgYduBLepWkR4te2yR9ss82iyRtLdrmX0de5bFx9P7TWPSqRr53/yp2dnaXujpmZqNu2IEfEX+IiIURsRA4HtgB3NzPpvf2bBcRXxzu5+0LH1l0KJvaO7mheXWpq2JmNupGq0vnVODZiHhhlPZXEq9bMIPjD5zBFfc8R1d3vtTVMTMbVaMV+OcB1w+w7g2Slkv6paSjB9qBpMWSmiU1t7aWZthiSXxk0SGs3bKTWx9dV5I6mJmNlREHvqQq4B3AT/pZ/QhwYEQcC/w3cMtA+4mIKyKiKSKaGhsbR1qtYTvliFkcsd8ULrv7WT8gxczKymi08M8EHomIDX1XRMS2iNiezN8GVEpqGIXPHDOSuHjRITzTsp2lK19xSGZmE9ZoBP75DNCdI2k/SUrmT0g+b9MofOaY+otXz2H+zMl85zfPEuFWvpmVhxEFvqRa4C3ATUVlF0m6KFl8F7BC0nLgUuC8mAAJWpHNsPjkg1m+egsPPjfuz09mZkMyosCPiPaIqI+IrUVll0fE5cn8tyLi6Ig4NiJOjIgHRlrhfeVdxx9AQ121h042s7LhO20HUFOZ5cKTDuLepzfy2Jotpa6OmdmIOfD34H0nzmfapEo+d/Pj7Ory3bdmNrE58PdgSk0l3zj3WFas3ca/3LLCP+Ca2YTmwB/EqUfO5hOnHMpPlq3h+oc85IKZTVwO/CG45LTDefPhjXzh1id4dLX7881sYnLgD0E2I/7rvIXMmlrNxdcuY9P2jlJXycxsrznwh2j65Couf9/xbG7v5OPX/56cB1czswnGgb8Xjpk7jS+fcwwPPLuJ/7jjj6WujpnZXnHg76V3N83jr18/n8vvfpbbV6wvdXXMzIbMgT8Mn3/7URw7bzp/f8NynmnZXurqmJkNiQN/GKorslz23uOoqcxy0bXL2N6RK3WVzMwG5cAfpv2nT+K/z38tz7Vu5x9/utw3ZZnZuOfAH4E3HtrAP55xBLc9/iJX3vt8qatjZrZHDvwR+vDJB3PG0fvx1duf4sFnPZSymY1fDvwRksTX3v0aFtRP5qM/fIQVa7cO/iYzsxIYjWfarpL0uKRHJTX3s16SLpX0jKTHJB030s8cb6bUVHLlBa9jUmWW9/zPg9z9x9I8hN3MbE9Gq4X/5xGxMCKa+ll3JnBY8loMXDZKnzmuHNRQy00feSPz62u58OqH+emyNaWukpnZbvZFl87ZwPej4LfAdElz9sHn7nOzp9Zww4dP5PUHz+TTP1nOt+96xlfvmNm4MRqBH8AdkpZJWtzP+rlA8bjCa5KysjSlppLvffAEzlm4P1/71R/451tW0J136JtZ6VWMwj5Oioi1kmYBSyU9FRH37O1OkpPFYoD58+ePQrVKp6oiwzfOXch+0yZx+d3P0tLWwaXnvZZJVdlSV83MUmzELfyIWJtMW4CbgRP6bLIWmFe0fEBS1nc/V0REU0Q0NTY2jrRaJZfJiM+eeQT/9o6j+d+VG/jrK3/L5vbOUlfLzFJsRIEvqVbSlJ554HRgRZ/NbgU+kFytcyKwNSJSM+rYBW9cwGXvPY4n1m3jXZc9wOrNO0pdJTNLqZG28GcD90laDjwE/CIibpd0kaSLkm1uA54DngG+C3xkhJ854ZxxzByu+9Dr2dTeyTu/84Cv1TezktB4vIqkqakpmptfcUn/hPdMSxsXLHmYLTs6+Y93H8uZry7Li5XMrAQkLRvg0vhevtN2Hzp01hRu+sgbOWRWHRdf9wgf/eEjflyime0zDvx9bPbUGm68+I18+vTDueOJF3nLN+/h/y1f5+v1zWzMOfBLoDKb4WOnHMYvPvEm5s2YxMev/z0XXbuMlrZdpa6amZUxB34JHT57Cjde/Eb+6cwjuOsPrbzlG/dw0yNr3No3szHhwC+ximyGD7/5EH55yZs4dFYdn7phOR+6ppkXt7q1b2ajy4E/ThzSWMcNH34D//K2o7j/2Y285Rt38+OH/+TWvpmNGgf+OJLNiAtPOojbLzmZo/afymdufJz3XfU7HluzpdRVM7My4MAfhxY01HL9353Il84+mifWbeMd37qfD13zMI+v8Q1bZjZ8vvFqnGvb1cU1D6ziu/c+z9adXZx25Gw+edphHDN3WqmrZmbjyFBuvHLgTxDbdnVx9f2ruPLe59i2K8fpR83mktMO4+j9Hfxm5sAvS9t2dfG9+1Zx5X3P0bYrx1uPns0nTzucI+dMLXXVzKyEHPhlbOvOLpbc9zxL7nueto4cZx6zH3938sG8dt50JJW6ema2jznwU2Drji6uuv95vpcE/2Gz6ji3aR7vPG4uDXXVpa6eme0jDvwU2d6R4+fL1/Hj5tX8/k9bqMiI046czXteN4+TD28km3Gr36ycOfBT6o8b2rjh4dXc9Pu1bG7vZL+pNfzV8XM5t2keB9bXlrp6ZjYGHPgp15nLc+fKDdzQvJq7/9hKPuDEg2fyruPnceoRs5hRW1XqKprZKBnTwJc0D/g+hadeBXBFRPxXn20WAT8Dnk+KboqILw62bwf+6Fu/dSc3LlvDDc1r+NPmHWQExx84g1OPnM2pR8zi0Fl1/rHXbAIb68CfA8yJiEeS59ouA86JiCeLtlkEfDoi3rY3+3bgj518Pnhs7VZ+vXID/7uyhSfXbwNg/szJnHLELE49chavP6ieqgrfhG02kQwl8CuGu/PkQeTrk/k2SSuBucCTe3yjlVQmIxbOm87CedP51OmvYv3Wndy5soVfP9XC9Q/9iasfWEVddQVvOqyBU4+czUmHNrDftJpSV9vMRsGo9OFLWgDcAxwTEduKyhcBNwJrgHUUWvtPDLCPxcBigPnz5x//wgsvjLhetnd2dnZz/zMbufOpFn791AY2bCs8fvGAGZM4YcFMXnfQTF63YAaHNLr7x2y82Sc/2kqqA+4GvhIRN/VZNxXIR8R2SWcB/xURhw22T3fplF5E8MS6bfzu+c00r9rMw6s2s3F7JwAzJlfStGBm70ng6P2nUpl1F5BZKY154EuqBH4O/CoivjGE7VcBTRGxcU/bOfDHn4jg+Y3tNK96iYeSE8ALm3YAMKkyy7HzpnH0/tM4cs5UjpozlUNn1fl3ALN9aEz78FX4m/4qYOVAYS9pP2BDRISkEygMx7xpuJ9ppSOJgxvrOLixjnNfNw+Alm27eHjVSzy8ajO//9NLXPvbF+jI5QGozIrDZk3hqP2n9p4EjpozlWmTK0t5GGapNpKrdE4C7gUeB/JJ8eeA+QARcbmkjwEXAzlgJ/CpiHhgsH27hT8x5brzrNrUzpPr23hy3TaeXL+NJ9dtY+P2jt5t5k6fxKGz6jiooZaDG2s5qKHw2n/aJDK+G9hs2HzjlY0LLW27WFl0EniudTvPb2xnR2d37zbVFZne8O95LWioZe70ScyeWuOhIcwGMaZdOmZDNWtKDbOm1PDmwxt7yyKClrYOnmtt5/mN7Ty/sXAS+MOGNpY+uYFc/uWGSEVG7DethrnTJzF3xiQOSKb7T5/E3OmFaU1lthSHZjahOPCtJCQxe2oNs6fW8IZD6ndbl+vOs+alnaza1M7aLTtZ+9LO3umDz25iw7Zd5Pv8YTpjcmXhxDK1umhamJ9dVOYTg6WZA9/GnYpshgVJl05/urrzvLh1124ngw3bdtHS1kHLtl0807Kd1raO3f5K6DGluoKZdVXMmFxFfW0VM2pfns6srWLm5Cpm1hWmMyZXMaWmwr8tWNlw4NuEU5nNMG/mZObNnDzgNvl88NKOTlraOnpPBq3Ja3N7J5vbO1m/dRdPrNvG5vZOOrvz/e5HKpwkpk+uYtqkysJrcmXv/PRJlUydVMmUmgrqqiuSaSV1yXJddYV/f7Bxw4FvZSmTEfV11dTXVQ/6+MeIYEdnd++JYHN7J5vaO9m6s4utO5Lpzi62JNN1W3eybWcXW3Z09ftXRF+1VdneE0BtdQW1VRXUVmeZXNWznGVydQV1vWWFaU1llknJq6YyU1iuylJTmaWmIkOFb3azveTAt9STVAje6oo9/tXQV8+JYuvOLto7cmzblWN7R47tu3Js7+iiLVlu21Uoa+voor2jmx2dOdZt6aK9M9e7XHzF0lBVZlUI/54TQkVyQqjIUp2cIHpODj3bVFdkqarIUF2RSabZovnCtGe+MluYr8xmqMoWppVZ7Vbm7q6JxYFvNkzFJ4qRyueDHV3d7OjI0d7ZTXtHjo5cNzs78+zs6mZXVzc7u7rpSKY7O/PsynWzs7M72a6bXV2Fsl1d3bTtytHa1kFHLl9Yl5R35vKv+MF7JLIZUZkVlZkMlRUZKjLqPVH0zFdWZKjMiIpsYTmbERWZwskjm2xTkayvyGSSqchmMsk0We6nPFu8frf5DNkMvdtm1LMeMip8TiZTqH9WIpNMs5mX5zMZCtOe9Um5xG7zE2lcKQe+2TiQyai3z3+s5brzdOTydOaKp910JMsduW66uoOuXJ6u7jyd3Xm6uoPOZLm3LBd0dneT6w46u/PkuqN3Xc98V++0UNaey5HLB13dQXc+2S6fp7s76MoHuWS77ghy+aA7eY1nUuEkkknCP9O7rN3W9Zw4itdnMrtv21BbzQ0XvWHM6urAN0uZimyh/792gjzjPqIQ+j0ngN5pd57uePmkUHyC6Lucy+fJ56E7gnzRunzsPs3lI/m8wrZRtP98Up5P9lFYX6hfPpLy3uWisnwQkOzj5fXd+d237Y5gas3YRrID38zGNSnp7vEtFCPmn/nNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZinhwDczSwkHvplZSozLRxxKagVeGObbG4CNo1idUiu344HyO6ZyOx4ov2Mqt+OBVx7TgRHRONDGME4DfyQkNQ/2XMeJpNyOB8rvmMrteKD8jqncjgeGd0zu0jEzSwkHvplZSpRj4F9R6gqMsnI7Hii/Yyq344HyO6ZyOx4YxjGVXR++mZn1rxxb+GZm1g8HvplZSpRN4Es6Q9IfJD0j6bOlrs9okLRK0uOSHpXUXOr6DIekJZJaJK0oKpspaamkp5PpjFLWcW8McDxfkLQ2+Z4elXRWKeu4NyTNk3SXpCclPSHpkqR8In9HAx3ThPyeJNVIekjS8uR4/i0pP0jS75LM+7GkqkH3VQ59+JKywB+BtwBrgIeB8yPiyZJWbIQkrQKaImLC3jAi6WRgO/D9iDgmKft3YHNEfDU5Oc+IiM+Usp5DNcDxfAHYHhH/Ucq6DYekOcCciHhE0hRgGXAO8EEm7nc00DGdywT8nlR4SnptRGyXVAncB1wCfAq4KSJ+JOlyYHlEXLanfZVLC/8E4JmIeC4iOoEfAWeXuE4GRMQ9wAnZaNAAAAPvSURBVOY+xWcD1yTz11D4xzghDHA8E1ZErI+IR5L5NmAlMJeJ/R0NdEwTUhRsTxYrk1cApwA/TcqH9B2VS+DPBVYXLa9hAn/BRQK4Q9IySYtLXZlRNDsi1ifzLwKzS1mZUfIxSY8lXT4TpvujmKQFwGuB31Em31GfY4IJ+j1Jykp6FGgBlgLPAlsiIpdsMqTMK5fAL1cnRcRxwJnAR5PuhLIShT7Fid6veBlwCLAQWA98vbTV2XuS6oAbgU9GxLbidRP1O+rnmCbs9xQR3RGxEDiAQo/GEcPZT7kE/lpgXtHyAUnZhBYRa5NpC3AzhS+6HGxI+ll7+ltbSlyfEYmIDck/yDzwXSbY95T0C98IXBcRNyXFE/o76u+YJvr3BBARW4C7gDcA0yVVJKuGlHnlEvgPA4clv1pXAecBt5a4TiMiqTb5wQlJtcDpwIo9v2vCuBW4IJm/APhZCesyYj3BmHgnE+h7Sn4QvApYGRHfKFo1Yb+jgY5pon5PkholTU/mJ1G4OGUlheB/V7LZkL6jsrhKByC5xOo/gSywJCK+UuIqjYikgym06gEqgB9OxGOSdD2wiMJQrhuAzwO3ADcA8ykMg31uREyIH0IHOJ5FFLoJAlgFfLio/3tck3QScC/wOJBPij9Hoc97on5HAx3T+UzA70nSayj8KJul0Ei/ISK+mGTEj4CZwO+B90VExx73VS6Bb2Zme1YuXTpmZjYIB76ZWUo48M3MUsKBb2aWEg58M7OUcOBbakjqLhop8dHRHFVV0oLiETTNxqOKwTcxKxs7k9vTzVLJLXxLveS5A/+ePHvgIUmHJuULJP06GWzrTknzk/LZkm5OxidfLumNya6ykr6bjFl+R3JXJJI+kYzN/pikH5XoMM0c+JYqk/p06bynaN3WiHg18C0Kd2wD/DdwTUS8BrgOuDQpvxS4OyKOBY4DnkjKDwO+HRFHA1uAv0rKPwu8NtnPRWN1cGaD8Z22lhqStkdEXT/lq4BTIuK5ZNCtFyOiXtJGCg/S6ErK10dEg6RW4IDi29iTYXiXRsRhyfJngMqI+LKk2yk8NOUW4Jaisc3N9im38M0KYoD5vVE8jkk3L/9G9hfAtyn8NfBw0QiHZvuUA9+s4D1F0weT+QcojLwK8F4KA3IB3AlcDL0Pppg20E4lZYB5EXEX8BlgGvCKvzLM9gW3NCxNJiVPDepxe0T0XJo5Q9JjFFrp5ydlHwe+J+kfgFbgb5LyS4ArJF1IoSV/MYUHavQnC1ybnBQEXJqMaW62z7kP31KvHB4WbzYU7tIxM0sJt/DNzFLCLXwzs5Rw4JuZpYQD38wsJRz4ZmYp4cA3M0uJ/w9jZsnkJJpoMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGWHf6eWbsVC",
        "colab_type": "text"
      },
      "source": [
        "# Inference Mode\n",
        "Now, it's time to try the model and ask him a few questins :)\n",
        "\n",
        "Helper function: to clean the text the user has entered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F25u2_84bxbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    This method takes a string, applies different text preprocessing \n",
        "    (characters replacement, removal of unwanted characters, removal of extra \n",
        "    whitespaces) operations and returns a string.\n",
        "    Arguments:\n",
        "      text: a string.\n",
        "    Returns:\n",
        "      a cleaned version of text.\n",
        "    \"\"\"\n",
        "    \n",
        "    import re\n",
        "    \n",
        "    text = str(text)\n",
        "    \n",
        "    # REPLACEMENT\n",
        "    text = re.sub('\\\"', '\\'', text)\n",
        "    text = re.sub(\"“\", '\\'', text)\n",
        "    text = re.sub(\"”\", '\\'', text)\n",
        "    text = re.sub('’', '\\'', text)\n",
        "    text = re.sub('\\[','(', text)\n",
        "    text = re.sub('\\]',')', text)\n",
        "    text = re.sub('\\{','(', text)\n",
        "    text = re.sub('\\}',')', text)\n",
        "    text = re.sub(\"([?.!,:;'?!+\\-*/=%$@&()])\", r\" \\1 \", text)\n",
        "\n",
        "    pattern = re.compile('[^a-zA-Z0-9_\\.\\,\\:\\;\\'\\?\\!\\+\\-\\*\\/\\=\\%\\$\\@\\&\\(\\)]')\n",
        "    # remove unwanted characters\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    \n",
        "    # lower case the characters in the string\n",
        "    text = text.lower()\n",
        "    \n",
        "    # REMOVAL OF EXTRA WHITESPACES\n",
        "    # remove duplicated spaces\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    # remove leading and trailing spaces\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "894XvPzNb7vH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LVX2z55b_kv",
        "colab_type": "text"
      },
      "source": [
        "The following fucntion passes a sentence that has been entered by the user to the model and returns its answer along with the input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rUgD4MecAdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    \"\"\"\n",
        "    This function takes a sentence (question) and returns the model's output\n",
        "    (answer) to it.\n",
        "    Arguemnts:\n",
        "      sentence: a string.\n",
        "    Returns:\n",
        "      result: a string, representing model's output to the input.\n",
        "      sentence: a string, the input sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    # clean the input sentence (question) to prepare for the encoder\n",
        "    sentence = clean_text(sentence)\n",
        "    sentence = '<start> ' + sentence + ' <end>'\n",
        "\n",
        "    # tokenize the input sentence and pad zeros if its length is less than\n",
        "    # maximum sequence length.\n",
        "    inputs = [text_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  \n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    # initilize the hidden state of the encoder\n",
        "    enc_hidden = (tf.zeros((1, units)), \n",
        "                  tf.zeros((1, units)), \n",
        "                  tf.zeros((1, units)), \n",
        "                  tf.zeros((1, units)))\n",
        "    \n",
        "    enc_output, enc_hidden, enc_c = encoder(inputs, enc_hidden)\n",
        "    \n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([text_tokenizer.word_index['<start>']], 0)\n",
        "    \n",
        "    # generate answer, where the maximum length for the answer is equal\n",
        "    # to max_length_targ=32\n",
        "    for t in range(max_length_targ):\n",
        "      predictions, dec_hidden, attention_weights = decoder(dec_input, \n",
        "                                                          dec_hidden, \n",
        "                                                          enc_output)\n",
        "\n",
        "      predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "      result += text_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "      if text_tokenizer.index_word[predicted_id] == '<end>':\n",
        "        return result, sentence\n",
        "\n",
        "      # the predicted ID is fed back into the model\n",
        "      dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swhPdcLhcNuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def answer(sentence):\n",
        "  \"\"\"\n",
        "  This function takes an input sentence by the user and prints the \n",
        "  model's answer along with the user's input sentence.\n",
        "  Arguments:\n",
        "      sentence: a string.\n",
        "  \"\"\"\n",
        "\n",
        "  result, sentence = evaluate(sentence)\n",
        "\n",
        "  print(f'INPUT: {sentence}')\n",
        "  print(f'CHATBOT ANSWER: {result}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52LmYigxcYo4",
        "colab_type": "text"
      },
      "source": [
        "Let's try to talk to the chatbot:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPv7nbKcZo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "fa5a8546-db97-435a-ed21-bec430da39ba"
      },
      "source": [
        "answer('tell me something funny')\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> tell me something funny <end>\n",
            "CHATBOT ANSWER: think of the other hand , but the other monster says , at least a boy i ' ve had to nail them put in old joke . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rby0I7kGcddX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00902626-bff9-4914-97ea-861e40c040f9"
      },
      "source": [
        "answer('What is it that you want in life?')\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is it that you want in life ? <end>\n",
            "CHATBOT ANSWER: me : a third door . 2 : oh , we ' <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvLfMiJJcpMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6439a359-74e4-4aa3-df89-76a90daf3390"
      },
      "source": [
        "answer(\"you're so fun\")\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> you ' re so fun <end>\n",
            "CHATBOT ANSWER: you ' re a puppy . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXKLi3h4c1tK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "829c4b34-2ccf-430d-b1e4-cb7febed2ddd"
      },
      "source": [
        "answer(\"do you like annoying people?\")\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> do you like annoying people ? <end>\n",
            "CHATBOT ANSWER: because i ' m a pain in the bathroom and hold the stuff in the bathroom and hold the stuff in the bathroom and hold the stuff in the bathroom and hold \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4yq_0_Yc8aT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1e99ae5-4fa2-4e85-ffe6-eb820241153b"
      },
      "source": [
        "answer('are you my friend?')\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> are you my friend ? <end>\n",
            "CHATBOT ANSWER: because your stories ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FJcHyoidBsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5b842f1a-b281-4929-b038-9228ee8937b8"
      },
      "source": [
        "answer(\"what is your favorite movie?\")\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is your favorite movie ? <end>\n",
            "CHATBOT ANSWER: she ' s not god : and it ' s a well earthquake in sucking . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd7uqq-hdJ5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de742f77-1c39-4fcd-c200-b0fa6925e7fe"
      },
      "source": [
        "answer(\"how do you sleep at night?\")\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how do you sleep at night ? <end>\n",
            "CHATBOT ANSWER: i carry your homework , mostly . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I4jNQTadVpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e0b90c4-fec1-439d-ac0e-872c6f816c0c"
      },
      "source": [
        "answer(\"what will happen if you went inside a black hole?\")\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what will happen if you went inside a black hole ? <end>\n",
            "CHATBOT ANSWER: i don ' t know either . it must be out of your waitress . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKgVQ-JzdbDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "35e0f5ba-cf99-47bb-ca82-09a0526a4e51"
      },
      "source": [
        "answer('If we count sheep to fall asleep, what do they count?')\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> if we count sheep to fall asleep , what do they count ? <end>\n",
            "CHATBOT ANSWER: would , eggs <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7U1bSBMdfo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c5ff354c-6aeb-456c-da67-560563e7e60b"
      },
      "source": [
        "answer(\"Why do people order double cheese burgers, large fries, and a diet coke?\")\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> why do people order double cheese burgers , large fries , and a diet coke ? <end>\n",
            "CHATBOT ANSWER: because the shits don ' t like there , but they like . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzBCs138di4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ab77667-a730-48f0-e2a0-de54cfcf35d9"
      },
      "source": [
        "answer(\"What is always coming, but never arrives?\")\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is always coming , but never arrives ? <end>\n",
            "CHATBOT ANSWER: <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357po0YGdodB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a823f05b-5f70-4fad-a5ed-d05b7760acde"
      },
      "source": [
        "answer(\"who is the most stupid person you know?\")\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> who is the most stupid person you know ? <end>\n",
            "CHATBOT ANSWER: and . who is left ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQTsCVQvdvhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0530c415-0475-40d5-91fc-e9c18bb26b37"
      },
      "source": [
        "answer(\"knock knock\")\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> knock knock <end>\n",
            "CHATBOT ANSWER: who ' s there ? . who ? is between us . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPHLRFR8dzuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b1bddcd-910f-4aa1-d2e5-1366977a58c3"
      },
      "source": [
        "answer(\"tell me a joke\")\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> tell me a joke <end>\n",
            "CHATBOT ANSWER: think - ' <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnUZiEDId4M9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "982e5f3e-0d6a-4121-dc01-1b4298707b76"
      },
      "source": [
        "answer(\"Do you exercise?\")\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> do you exercise ? <end>\n",
            "CHATBOT ANSWER: because i put a coffee shop . me : hey , i am ! <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlXtKR0Bd97l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c6fc7cb7-ccfe-4b54-ecef-1e2d34d7c8e5"
      },
      "source": [
        "answer(\"How do you keep a clear mind during hard times?\")\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how do you keep a clear mind during hard times ? <end>\n",
            "CHATBOT ANSWER: give him a bus <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2XIZ-6GeBoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e6dacfa9-c3e7-4c6e-c199-7d321a791ba1"
      },
      "source": [
        "answer(\"who is your best friend?\")\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> who is your best friend ? <end>\n",
            "CHATBOT ANSWER: robert ' ' yesterday . ' <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZdoEhNDeH66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cdab9ae6-4823-40e3-8812-eff87128fb94"
      },
      "source": [
        "answer(\"what do you have in mind?\")\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what do you have in mind ? <end>\n",
            "CHATBOT ANSWER: me : struggling , for me : ' my backpack ? me : ' my friend told me the bartender , for the tape ! ' <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8l3sC72erSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d37298e-4b15-4353-cfc3-95a6461d78eb"
      },
      "source": [
        "answer(\"who is you favorite singer?\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> who is you favorite singer ? <end>\n",
            "CHATBOT ANSWER: <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7e9jnWXesNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "27e0689f-d911-402b-ca2e-93d895475bff"
      },
      "source": [
        "answer(\"Are you enjoying this conversation?\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> are you enjoying this conversation ? <end>\n",
            "CHATBOT ANSWER: because you ' re 10 / 10 <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDsVxFvvezBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7851347f-be5c-471b-a0c8-144618699534"
      },
      "source": [
        "answer(\"Do you know Google assistant?\")\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> do you know google assistant ? <end>\n",
            "CHATBOT ANSWER: i ' ve never let you a mean that has a mean that has a mean that has a mean that has a mean that has a mean that has a mean \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmxp7rWtez0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0fd4ac4-0da3-4774-fc79-238a33184d63"
      },
      "source": [
        "answer(\"what do you like to talk about the most?\")\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what do you like to talk about the most ? <end>\n",
            "CHATBOT ANSWER: go for granite . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOk9yvMpe4U4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b64118ee-ae95-4c1e-b821-b0d56d14f7df"
      },
      "source": [
        "answer(\"Why do you like to talk about fire?\")\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> why do you like to talk about fire ? <end>\n",
            "CHATBOT ANSWER: me : you ' re already taken . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-KgZao1e7ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f52d5451-ed67-4805-9180-2a812d62e31f"
      },
      "source": [
        "answer(\"What was the best thing before sliced bread?\")\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what was the best thing before sliced bread ? <end>\n",
            "CHATBOT ANSWER: massive sandwiches <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBf7j1ZcfABd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cacdeb1b-9f39-4205-878c-7c738ad43d3d"
      },
      "source": [
        "answer(\"What is better than the FOUNTAIN OF YOUTH?\")\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is better than the fountain of youth ? <end>\n",
            "CHATBOT ANSWER: going to . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYqw_nKffDEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e05035d-bba5-437b-86c7-ddde5addf1b0"
      },
      "source": [
        "answer(\"Are you lazy?\")\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> are you lazy ? <end>\n",
            "CHATBOT ANSWER: because i ' m a bitch . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9-g_wrMfHFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07e67153-82f5-4be4-d236-4c77f87fc6f3"
      },
      "source": [
        "answer(\"How do you know that you'll never quit smoking?\")\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how do you know that you ' ll never quit smoking ? <end>\n",
            "CHATBOT ANSWER: when the fuck are you . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71qmGXp4fK7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae0f9f68-d428-45d8-fd56-25c230720d30"
      },
      "source": [
        "answer(\"When will you quit smoking?\")\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> when will you quit smoking ? <end>\n",
            "CHATBOT ANSWER: i just wrote three . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI4DbQ5ifOBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9bf055f1-9ad6-4334-9035-dce21004ab7d"
      },
      "source": [
        "answer(\"Who talks the most?\")\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> who talks the most ? <end>\n",
            "CHATBOT ANSWER: when the s 9 / 11 9 year old son says the one for the girl , the one is always in a way . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JLJVZAOfSAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "326cab78-0f3d-4123-c7a9-cc07a4ca1392"
      },
      "source": [
        "answer(\"Who lies the most?\")\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> who lies the most ? <end>\n",
            "CHATBOT ANSWER: a very big spider with a car with a car with a car with a car with a car with a car with a car with a car with a car with \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH3RWYXJfU1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8772246-27af-4ae8-a151-d41bfa2ac710"
      },
      "source": [
        "answer(\"What do you know about computers?\")\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what do you know about computers ? <end>\n",
            "CHATBOT ANSWER: you ' re not that you have to share this one . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuY4cToafXkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b92c45a9-3080-4cb8-af1a-365bf0778a43"
      },
      "source": [
        "answer(\"Where do like to travel?\")\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> where do like to travel ? <end>\n",
            "CHATBOT ANSWER: in a . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqkE9IvgfaXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "334a0d98-a8a4-463c-aef4-cbb79345cce7"
      },
      "source": [
        "answer(\"Which country do you want to visit?\")\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> which country do you want to visit ? <end>\n",
            "CHATBOT ANSWER: the song is the big metal . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlA0Jhk_ffD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b05b1283-b475-4013-dac2-034919284d9f"
      },
      "source": [
        "answer(\"Which type of music do you like?\")\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> which type of music do you like ? <end>\n",
            "CHATBOT ANSWER: i ' m a big metal fan , i ' m a big metal fan , i ' m a big metal fan , i ' m a big metal fan , \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho8dd2ckfh87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b4709a9b-c5ba-430a-dea6-587b28525890"
      },
      "source": [
        "answer(\"what's your job?\")\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what ' s your job ? <end>\n",
            "CHATBOT ANSWER: patient : mailman dr dog : * him * i don ' t give a crane . . . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl9L42RGflEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03bce2f1-9052-4cec-970c-f4f7265d472d"
      },
      "source": [
        "answer(\"Are you an artificial intelligence model?\")\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> are you an artificial intelligence model ? <end>\n",
            "CHATBOT ANSWER: an ass is over here . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKjJ8Qipfo-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1564e7c6-0b60-493e-aae0-cf04dc9ca43b"
      },
      "source": [
        "answer(\"How are you doing?\")\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how are you doing ? <end>\n",
            "CHATBOT ANSWER: me : * starts to respond but i shove my arm off her : word . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LkU3mrSfsmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3434ddbe-e79c-4b56-e0c3-b9bbc4ca8235"
      },
      "source": [
        "answer(\"How are you?\")\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how are you ? <end>\n",
            "CHATBOT ANSWER: not good , maria . clearly . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvPR-3dFfvn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c725723a-60cc-4cb9-f4df-5fa8324c8080"
      },
      "source": [
        "answer(\"How was your day?\")\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how was your day ? <end>\n",
            "CHATBOT ANSWER: you know , i thought ' ' . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6ASX8sWfylt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a185ae58-8957-4296-fef2-6f957aa7e67b"
      },
      "source": [
        "answer(\"Where do you vacation?\")\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> where do you vacation ? <end>\n",
            "CHATBOT ANSWER: the . home . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLwCBVkEf3DG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8ff0ec19-3d6c-477c-f98d-891146a5f035"
      },
      "source": [
        "answer(\"Thanks for your time.\")\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> thanks for your time . <end>\n",
            "CHATBOT ANSWER: that means a gun . ) <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlpG-isPf6Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c305791e-011e-4d9d-cec2-ac0545312ed1"
      },
      "source": [
        "answer(\"What is your least favorite food?\")\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is your least favorite food ? <end>\n",
            "CHATBOT ANSWER: your boat <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EktR9hzif-O8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6079a840-3816-49b2-c286-583a60cdb7fb"
      },
      "source": [
        "answer(\"What is the most hilarious childhood memory you can think of?\")\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is the most hilarious childhood memory you can think of ? <end>\n",
            "CHATBOT ANSWER: person with the most states the people called the people called the people called the people called the people called the people called the people called the people called the people called \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtWvSlizgBPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "138db0ab-9e08-482a-a7fe-1dc0b2ecc8f2"
      },
      "source": [
        "answer(\"Are you funny?\")\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> are you funny ? <end>\n",
            "CHATBOT ANSWER: no i ' m not laugh . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7dfNIeDgFWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b0f9e09b-b3be-44e7-a8a6-aa749c31c008"
      },
      "source": [
        "answer(\"Beethoven or Bach?\")\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> beethoven or bach ? <end>\n",
            "CHATBOT ANSWER: how do we got one . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JktyN4x2gIMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db187736-3eb8-4f95-8b27-03eda7da6d82"
      },
      "source": [
        "answer(\"How do you like your coffee?\")\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> how do you like your coffee ? <end>\n",
            "CHATBOT ANSWER: you go to cry because it was a week or mine . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0fw08VXgMSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b18574f-9cfe-4804-c82e-f0d9131cf9b0"
      },
      "source": [
        "answer(\"What is your favorite sport?\")\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is your favorite sport ? <end>\n",
            "CHATBOT ANSWER: <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF9GVoUNgQJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec83287a-53a9-4308-c9b6-80aa4ea2c679"
      },
      "source": [
        "answer(\"What is your favorite car?\")\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INPUT: <start> what is your favorite car ? <end>\n",
            "CHATBOT ANSWER: the . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrwjZ7qEgT7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWm7WQsygXmA",
        "colab_type": "text"
      },
      "source": [
        "Start a conversation with the chatbot:\n",
        "\n",
        "The following function takes an input sentence from the user and prints the model's answer to it until the user enters exit() to finish the conversation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WZs-gXkgYl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chat():\n",
        "    \"\"\"\n",
        "    This function takes input from the user and outputs the chatbot's answer\n",
        "    until the user inputs `exit()`\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Start your conversation with the chatbot!\")\n",
        "    print(\"If you want to end this conversation, enter: exit()\\nHave fun!\")  \n",
        "\n",
        "    while True:\n",
        "      # take user input\n",
        "      user_input = str(input('>>'))\n",
        "      \n",
        "      if user_input == 'exit()':\n",
        "        break\n",
        "\n",
        "      try:\n",
        "        # generate an answer for the user's question.\n",
        "        chatbot_answer, _ = evaluate(user_input)\n",
        "        print(chatbot_answer)\n",
        "      except:\n",
        "        # in case there's word out of chatbot vocabulary.\n",
        "        print(\"Oops! can't help you there! Try different words or restructure your sentence.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ovK5NNJgk9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0e18367b-d064-4edc-d978-adacd2050d37"
      },
      "source": [
        "chat()\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start your conversation with the chatbot!\n",
            "If you want to end this conversation, enter: exit()\n",
            "Have fun!\n",
            ">>Are you a man or a woman?\n",
            "because i want to c ' t we going to * * t - man - er she seems like a girl ' s best friend how to go in it <end> \n",
            ">>Are you a chat bot?\n",
            "Oops! can't help you there! Try different words or restructure your sentence.\n",
            ">>How do you plan for vacations?\n",
            "Oops! can't help you there! Try different words or restructure your sentence.\n",
            ">>How do you plan for holidays?\n",
            "it first google maps . <end> \n",
            ">>bye\n",
            "that ' s there are like a car <end> \n",
            ">>exit()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nUclib2hlTy",
        "colab_type": "text"
      },
      "source": [
        "As we notice, not all the answers generated by the model are good or valid answers and there's a lot to improve here. For example, there's some answers with repeated blocks of words. Also, some of the answers are not valid responses to the questions and do not relate the topic being proposed in the question. This kind of performance is expected for a deep learning chatbot with this very small dataset but it's okay for a demo project which can be improved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP1oXOSpgokr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOnirwdPhsSH",
        "colab_type": "text"
      },
      "source": [
        "# What can we do to improve performance:\n",
        "**More data**: if we want to have good performance with somewhat impressive responses, we need to train on a lot more data, maybe millions of pairs. However, training on a large scale dataset requires more computational power (maybe a more powerful GPU) and a more sophisticated model with more layers and units, let alone finding and acquiring such dataset.\n",
        "\n",
        "**DISCLAIMER**: the model has been trained on 175,671 question-answer pairs which have been gathered from different sources like reddit, and it turns out that some of the model's answers are impolite, just something to be aware of.\n",
        "\n",
        "## References:\n",
        " - Effective Approaches to Attention-based Neural Machine Translation\n",
        "\n",
        "  - Neural machine translation with attention\n",
        "\n",
        "  - Neural Machine Translation by Jointly Learning to Align and Translate\n",
        "\n",
        "   - Neural Machine Translation (seq2seq) Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8xtTTOSiKfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}